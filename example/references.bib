@inproceedings{turbotransformers,
  author       = {Jiarui Fang and
                  Yang Yu and
                  Chengduo Zhao and
                  Jie Zhou},
  title        = {TurboTransformers: an efficient {GPU} serving system for transformer
                  models},
  booktitle    = {PPoPP '21: 26th {ACM} {SIGPLAN} Symposium on Principles and Practice
                  of Parallel Programming, Virtual Event, Republic of Korea, February
                  27- March 3, 2021},
  pages        = {389--402},
  publisher    = {{ACM}},
  year         = {2021},
  url          = {https://doi.org/10.1145/3437801.3441578},
  doi          = {10.1145/3437801.3441578},
  timestamp    = {Sun, 12 Jun 2022 19:46:08 +0200},
  biburl       = {https://dblp.org/rec/conf/ppopp/FangYZZ21.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@software{anthropic2025claudecode,
  author = {{Anthropic}},
  title = {Claude Code: An Agentic Coding Tool for Terminal-Based Development},
  year = {2025},
  url = {https://github.com/anthropics/claude-code},
  note = {GitHub repository},
  howpublished = {\url{https://github.com/anthropics/claude-code}}
}

@book{ostep,
  author    = {Remzi H. Arpaci-Dusseau and Andrea C. Arpaci-Dusseau},
  title     = {Operating Systems: Three Easy Pieces},
  publisher = {Arpaci-Dusseau Books},
  year      = {2023},
  note      = {Chapter: CPU Scheduling}
}

@article{mitra2025beyond,
  title={Beyond the Buzz: A Pragmatic Take on Inference Disaggregation},
  author={Mitra, Tiyasa and Borkar, Ritika and Bhatia, Nidhi and Matas, Ramon and Raj, Shivam and Mudigere, Dheevatsa and Zhao, Ritchie and Golub, Maximilian and Dutta, Arpan and Madduri, Sailaja and others},
  journal={arXiv preprint arXiv:2506.05508},
  year={2025}
}

@inproceedings{narayanan2021efficient,
  title={Efficient large-scale language model training on gpu clusters using megatron-lm},
  author={Narayanan, Deepak and Shoeybi, Mohammad and Casper, Jared and LeGresley, Patrick and Patwary, Mostofa and Korthikanti, Vijay and Vainbrand, Dmitri and Kashinkunti, Prethvi and Bernauer, Julie and Catanzaro, Bryan and others},
  booktitle={Proceedings of the international conference for high performance computing, networking, storage and analysis},
  pages={1--15},
  year={2021}
}

@book{dino,
  author    = {Abraham Silberschatz and Peter B. Galvin and Greg Gagne},
  title     = {Operating System Concepts},
  edition   = {9th},
  publisher = {Wiley},
  year      = {2012},
  isbn      = {978-1118063330}
}

@software{google2025geminicli,
  author = {{Google Gemini}},
  title = {Gemini CLI: An Open-Source AI Agent for Terminal Workflows},
  year = {2025},
  url = {https://github.com/google-gemini/gemini-cli},
  note = {GitHub repository},
  howpublished = {\url{https://github.com/google-gemini/gemini-cli}}
}

@misc{llmserving,
      title={LLMServingSim: A HW/SW Co-Simulation Infrastructure for LLM Inference Serving at Scale}, 
      author={Jaehong Cho and Minsu Kim and Hyunmin Choi and Guseul Heo and Jongse Park},
      year={2024},
      eprint={2408.05499},
      archivePrefix={arXiv},
      primaryClass={cs.DC},
      url={https://arxiv.org/abs/2408.05499}, 
}

@inproceedings{2024infinigen,
  title={{InfiniGen: Efficient Generative Inference of Large Language Models with Dynamic KV Cache Management}},
  author={Lee, Wonbeom and Lee, Jungi and Seo, Junghwan and Sim, Jaewoong},
  booktitle={OSDI},
  year={2024}
}

@article{2020reformer,
  title={Reformer: The efficient transformer},
  author={Kitaev, Nikita and Kaiser, {\L}ukasz and Levskaya, Anselm},
  journal={arXiv preprint arXiv:2001.04451},
  year={2020}
}

@article{qwen2.5,
      title={Qwen2.5-1M Technical Report}, 
      author={An Yang and Bowen Yu and Chengyuan Li and Dayiheng Liu and Fei Huang and Haoyan Huang and Jiandong Jiang and Jianhong Tu and Jianwei Zhang and Jingren Zhou and Junyang Lin and Kai Dang and Kexin Yang and Le Yu and Mei Li and Minmin Sun and Qin Zhu and Rui Men and Tao He and Weijia Xu and Wenbiao Yin and Wenyuan Yu and Xiafei Qiu and Xingzhang Ren and Xinlong Yang and Yong Li and Zhiying Xu and Zipeng Zhang},
      journal={arXiv preprint arXiv:2501.15383},
      year={2025}
}

@article{2024longrope,
  title={Longrope: Extending llm context window beyond 2 million tokens},
  author={Ding, Yiran and Zhang, Li Lyna and Zhang, Chengruidong and Xu, Yuanyuan and Shang, Ning and Xu, Jiahang and Yang, Fan and Yang, Mao},
  journal={arXiv preprint arXiv:2402.13753},
  year={2024}
}

@article{2024infinite,
  title={Infinite-llm: Efficient llm service for long context with distattention and distributed kvcache},
  author={Lin, Bin and Peng, Tao and Zhang, Chen and Sun, Minmin and Li, Lanbo and Zhao, Hanyu and Xiao, Wencong and Xu, Qi and Qiu, Xiafei and Li, Shen and others},
  journal={arXiv preprint arXiv:2401.02669},
  year={2024}
}

@article{gu2023mamba,
  title={Mamba: Linear-time sequence modeling with selective state spaces},
  author={Gu, Albert and Dao, Tri},
  journal={arXiv preprint arXiv:2312.00752},
  year={2023}
}

@article{gu2021efficiently,
  title={Efficiently modeling long sequences with structured state spaces},
  author={Gu, Albert and Goel, Karan and R{\'e}, Christopher},
  journal={arXiv preprint arXiv:2111.00396},
  year={2021}
}

@inproceedings{2024loongserve,
  title={{LoongServe: Efficiently Serving Long-context Large Language Models with Elastic Sequence Parallelism}},
  author={Wu, Bingyang and Liu, Shengyu and Zhong, Yinmin and Sun, Peng and Liu, Xuanzhe and Jin, Xin},
  booktitle={SOSP},
  year={2024}
}

@article{2024leave,
  title={Leave no context behind: Efficient infinite context transformers with infini-attention},
  author={Munkhdalai, Tsendsuren and Faruqui, Manaal and Gopal, Siddharth},
  journal={arXiv preprint arXiv:2404.07143},
  year={2024}
}

@article{2023longllmlingua,
  title={{LongLLMLingua: Accelerating and enhancing llms in long context scenarios via prompt compression}},
  author={Jiang, Huiqiang and Wu, Qianhui and Luo, Xufang and Li, Dongsheng and Lin, Chin-Yew and Yang, Yuqing and Qiu, Lili},
  journal={arXiv preprint arXiv:2310.06839},
  year={2023}
}

@article{2021sequence,
  title={Sequence parallelism: Long sequence training from system perspective},
  author={Li, Shenggui and Xue, Fuzhao and Baranwal, Chaitanya and Li, Yongbin and You, Yang},
  journal={arXiv preprint arXiv:2105.13120},
  year={2021}
}

@misc{flashinfer,
    title = {{Accelerating Self-Attentions for LLM Serving with FlashInfer}},
    url = {https://flashinfer.ai/2024/02/02/introduce-flashinfer.html},
    author = {Ye, Zihao and Chen, Lequn and Lai, Ruihang and Zhao, Yilong and Zheng, Size and Shao, Junru and Hou, Bohan and Jin, Hongyi and Zuo, Yifei and Yin, Liangsheng and Chen, Tianqi and Ceze, Luis},
    month = {February},
    year = {2024}
}

@misc{MSFTBERT,
	date-added = {2022-12-07 01:43:51 -0800},
	date-modified = {2022-12-07 01:43:51 -0800},
	howpublished = {\url{https://cloudblogs.microsoft.com/opensource/2020/01/21/microsoft-onnx-open-source-optimizations-transformer-inference-gpu-cpu/}},
	title = {{Microsoft open sources breakthrough optimizations for transformer inference on GPU and CPU}}
}

@misc{llmperfblog,
	date-added = {2023-10-12},
	howpublished = {\url{https://www.databricks.com/blog/llm-inference-performance-engineering-best-practices}},
	title = {{LLM Inference Performance Engineering: Best Practices}}
}

@misc{gpt3-api,
	date-added = {2022-12-07 01:43:51 -0800},
	date-modified = {2022-12-07 01:43:51 -0800},
	howpublished = {\url{https://medium.com/modern-nlp/estimating-gpt3-api-cost-50282f869ab8}},
	title = {{Estimating GPT3 API Cost}}}

@misc{onnx-ms,
	date-added = {2022-12-07 01:43:51 -0800},
	date-modified = {2022-12-07 01:43:51 -0800},
	howpublished = {\url{https://onnxruntime.ai/about.html}},
	title = {{ONNX Runtime usage at Microsoft}}}

@misc{distilled-deploy,
	date-added = {2022-12-07 01:43:51 -0800},
	date-modified = {2022-12-07 01:43:51 -0800},
	howpublished = {\url{https://medium.com/data-science-at-microsoft/model-compression-and-optimization-why-\\think-bigger-when-you-can-think-smaller-\\216ec096f68b}},
	title = {{Model compression and optimization: Why think bigger when you can think smaller?}}}

@misc{batch-inference,
	date-added = {2022-12-07 01:43:51 -0800},
	date-modified = {2022-12-07 01:43:51 -0800},
	howpublished = {\url{https://mlinproduction.com/batch-inference-vs-online-inference/}},
	title = {{Batch Inference}}
}


@inproceedings{bert,
  author    = {Jacob Devlin and
               Ming{-}Wei Chang and
               Kenton Lee and
               Kristina Toutanova},
  title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
               Understanding},
  booktitle = {Proceedings of the 2019 Conference of the North American Chapter of
               the Association for Computational Linguistics: Human Language Technologies,
               {NAACL-HLT} 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long
               and Short Papers)},
  pages     = {4171--4186},
  publisher = {Association for Computational Linguistics},
  year      = {2019},
  url       = {https://doi.org/10.18653/v1/n19-1423},
  doi       = {10.18653/v1/n19-1423},
  timestamp = {Mon, 26 Sep 2022 12:21:55 +0200},
  biburl    = {https://dblp.org/rec/conf/naacl/DevlinCLT19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

 @misc{amex,
	date-added = {2022-12-07 01:43:51 -0800},
	date-modified = {2022-12-07 01:43:51 -0800},
	howpublished = {\url{https://blogs.nvidia.com/blog/2020/10/05/american-express-nvidia-ai/}},
	title = {{American Express Adopts NVIDIA AI to Help Prevent Fraud and Foil Cybercrime}}}

 @inproceedings{clipper,
  title={Clipper: A $\{$Low-Latency$\}$ Online Prediction Serving System},
  author={Crankshaw, Daniel and Wang, Xin and Zhou, Guilio and Franklin, Michael J and Gonzalez, Joseph E and Stoica, Ion},
  booktitle={14th USENIX Symposium on Networked Systems Design and Implementation (NSDI 17)},
  pages={613--627},
  year={2017}
}

@article{tirumala1999iperf,
  title={Iperf: The TCP/UDP bandwidth measurement tool},
  author={Tirumala, Ajay},
  journal={http://dast. nlanr. net/Projects/Iperf/},
  year={1999}
}


%%article{appendix,
%  title={Supplementary material for paper #334 (OSDI 23)},
%  author={Anonymous},
%  journal={},
%  year={2022}
%}

@article{ILSVRC15,
Author = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
Title = {{ImageNet Large Scale Visual Recognition Challenge}},
Year = {2015},
journal   = {International Journal of Computer Vision (IJCV)},
doi = {10.1007/s11263-015-0816-y},
volume={115},
number={3},
pages={211-252}
}

@inproceedings{williams2018broadmnli,
   author    = {Williams, Adina and Nangia, Nikita and Bowman, Samuel R.},
   title = {A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference},
   booktitle = {Proceedings of NAACL-HLT},
   year = 2018
 }

 @online{twitter-trace,
  author = {Twitter, Inc.},
  title = {ArchiveTeam JSON Download of Twitter Stream 2018-04},
  year = 2018,
  url = {https://archive.org/details/archiveteam-twitter-stream-2018-04},
  urldate = {2018-05-23}
}

@inproceedings{cocktail,
  title={Cocktail: A Multidimensional Optimization for Model Serving in Cloud},
  author={Gunasekaran, Jashwant Raj and Mishra, Cyan Subhra and Thinakaran, Prashanth and Sharma, Bikash and Kandemir, Mahmut Taylan and Das, Chita R},
  booktitle={19th USENIX Symposium on Networked Systems Design and Implementation (NSDI 22)},
  pages={1041--1057},
  year={2022}
}

@inproceedings{infaas,
  title={$\{$INFaaS$\}$: Automated Model-less Inference Serving},
  author={Romero, Francisco and Li, Qian and Yadwadkar, Neeraja J and Kozyrakis, Christos},
  booktitle={2021 USENIX Annual Technical Conference (USENIX ATC 21)},
  pages={397--411},
  year={2021}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@article{bbr,
  title={Bbr: Congestion-based congestion control: Measuring bottleneck bandwidth and round-trip propagation time},
  author={Cardwell, Neal and Cheng, Yuchung and Gunn, C Stephen and Yeganeh, Soheil Hassas and Jacobson, Van},
  journal={Queue},
  volume={14},
  number={5},
  pages={20--53},
  year={2016},
  publisher={ACM New York, NY, USA}
}

@inproceedings{clockwork,
  title={Serving $\{$DNNs$\}$ like Clockwork: Performance Predictability from the Bottom Up},
  author={Gujarati, Arpan and Karimi, Reza and Alzayat, Safya and Hao, Wei and Kaufmann, Antoine and Vigfusson, Ymir and Mace, Jonathan},
  booktitle={14th USENIX Symposium on Operating Systems Design and Implementation (OSDI 20)},
  pages={443--462},
  year={2020}
}

@inproceedings{swayam,
  title={Swayam: distributed autoscaling to meet slas of machine learning inference services with resource efficiency},
  author={Gujarati, Arpan and Elnikety, Sameh and He, Yuxiong and McKinley, Kathryn S and Brandenburg, Bj{\"o}rn B},
  booktitle={Proceedings of the 18th ACM/IFIP/USENIX middleware conference},
  pages={109--120},
  year={2017}
}

@misc{cocktail-repo,
	howpublished = {\url{https://github.com/jashwantraj92/cocktail}},
	title = {{Cocktail repository}}}

@misc{pytorch-version,
	howpublished = {\url{https://github.com/pytorch/pytorch/commit/8a1a93a}},
	title = {{Pytorch version 1.12.0a0+8a1a93a}}}

@misc{amp,
	howpublished = {\url{https://pytorch.org/docs/stable/amp.html}},
	title = {{Pytorch AMP}}}

@article{grpc,
  title={GRPC: A communication cooperation mechanism in distributed systems},
  author={Wang, Xingwei and Zhao, Hong and Zhu, Jiakeng},
  journal={ACM SIGOPS Operating Systems Review},
  volume={27},
  number={3},
  pages={75--86},
  year={1993},
  publisher={ACM New York, NY, USA}
}

@misc{triton,
	howpublished = {\url{https://developer.nvidia.com/nvidia-triton-inference-server}},
	title = {{NVIDIA Triton Inference Server}}}

@article{majority-voting,
  title={Dynamic weighted majority: An ensemble method for drifting concepts},
  author={Kolter, J Zico and Maloof, Marcus A},
  journal={The Journal of Machine Learning Research},
  volume={8},
  pages={2755--2790},
  year={2007},
  publisher={JMLR. org}
}

@inproceedings{weighted-averaging,
  title={Robust Bayesian linear classifier ensembles},
  author={Cerquides, Jes{\'u}s and M{\'a}ntaras, Ramon L{\'o}pez de},
  booktitle={European Conference on Machine Learning},
  pages={72--83},
  year={2005},
  organization={Springer}
}

@inproceedings{power-of-ensembles,
  title={The power of ensembles for active learning in image classification},
  author={Beluch, William H and Genewein, Tim and N{\"u}rnberger, Andreas and K{\"o}hler, Jan M},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={9368--9377},
  year={2018}
}

@article{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{spot-instances,
  title={Using burstable instances in the public cloud: Why, when and how?},
  author={Wang, Cheng and Urgaonkar, Bhuvan and Nasiriani, Neda and Kesidis, George},
  journal={Proceedings of the ACM on Measurement and Analysis of Computing Systems},
  volume={1},
  number={1},
  pages={1--28},
  year={2017},
  publisher={ACM New York, NY, USA}
}

@misc{docker,
	howpublished = {\url{https://www.docker.com/}},
	title = {{Docker}}}

@inproceedings{half-precision-exploiting,
  title={Exploiting half precision arithmetic in Nvidia GPUs},
  author={Ho, Nhut-Minh and Wong, Weng-Fai},
  booktitle={2017 IEEE High Performance Extreme Computing Conference (HPEC)},
  pages={1--7},
  year={2017},
  organization={IEEE}
}

@inproceedings{synergy,
  title={Looking Beyond $\{$GPUs$\}$ for $\{$DNN$\}$ Scheduling on $\{$Multi-Tenant$\}$ Clusters},
  author={Mohan, Jayashree and Phanishayee, Amar and Kulkarni, Janardhan and Chidambaram, Vijay},
  booktitle={16th USENIX Symposium on Operating Systems Design and Implementation (OSDI 22)},
  pages={579--596},
  year={2022}
}

@misc{triton-batch,
	howpublished = {\url{https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user\_guide/model\_configuration.html#dynamic-batcher}},
	title = {{NVIDIA Triton Dynamic Batching}}}

@inproceedings{efficientnet,
  title={Efficientnet: Rethinking model scaling for convolutional neural networks},
  author={Tan, Mingxing and Le, Quoc},
  booktitle={International conference on machine learning},
  pages={6105--6114},
  year={2019},
  organization={PMLR}
}

@inproceedings{imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}

@inproceedings{gujarati2020serving,
  title={Serving $\{$DNNs$\}$ like Clockwork: Performance Predictability from the Bottom Up},
  author={Gujarati, Arpan and Karimi, Reza and Alzayat, Safya and Hao, Wei and Kaufmann, Antoine and Vigfusson, Ymir and Mace, Jonathan},
  booktitle={14th USENIX Symposium on Operating Systems Design and Implementation (OSDI 20)},
  pages={443--462},
  year={2020}
}

@inproceedings{hazelwood2018applied,
  title={Applied machine learning at facebook: A datacenter infrastructure perspective},
  author={Hazelwood, Kim and Bird, Sarah and Brooks, David and Chintala, Soumith and Diril, Utku and Dzhulgakov, Dmytro and Fawzy, Mohamed and Jia, Bill and Jia, Yangqing and Kalro, Aditya and others},
  booktitle={2018 IEEE International Symposium on High Performance Computer Architecture (HPCA)},
  pages={620--629},
  year={2018},
  organization={IEEE}
}



@misc{google-model-ensembles-faster,
	howpublished = {\url{https://ai.googleblog.com/2021/11/model-ensembles-are-faster-than-you.html}},
	title = {{Model ensembles are faster than you think}}}

@misc{amazon-sagemaker,
	howpublished = {\url{https://aws.amazon.com/sagemaker/}},
	title = {{Amazon SageMaker}}}

@misc{azure-mlaas,
	howpublished = {\url{https://azure.microsoft.com/en-us/products/machine-learning/#product-overview}},
	title = {{Azure Machine Learning as a service}}}

 @inproceedings{senior2014improving,
  title={Improving DNN speaker independence with i-vector inputs},
  author={Senior, Andrew and Lopez-Moreno, Ignacio},
  booktitle={2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={225--229},
  year={2014},
  organization={IEEE}
}

@inproceedings{bartlett2005recognizing,
  title={Recognizing facial expression: machine learning and application to spontaneous behavior},
  author={Bartlett, Marian Stewart and Littlewort, Gwen and Frank, Mark and Lainscsek, Claudia and Fasel, Ian and Movellan, Javier},
  booktitle={2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)},
  volume={2},
  pages={568--573},
  year={2005},
  organization={IEEE}
}

@inproceedings{mobilenet,
  title={Searching for mobilenetv3},
  author={Howard, Andrew and Sandler, Mark and Chu, Grace and Chen, Liang-Chieh and Chen, Bo and Tan, Mingxing and Wang, Weijun and Zhu, Yukun and Pang, Ruoming and Vasudevan, Vijay and others},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={1314--1324},
  year={2019}
}

@inproceedings{socher2013recursive,
  title={Recursive deep models for semantic compositionality over a sentiment treebank},
  author={Socher, Richard and Perelygin, Alex and Wu, Jean and Chuang, Jason and Manning, Christopher D and Ng, Andrew Y and Potts, Christopher},
  booktitle={Proceedings of the 2013 conference on empirical methods in natural language processing},
  pages={1631--1642},
  year={2013}
}

@article{wolf2019huggingface,
  title={Huggingface's transformers: State-of-the-art natural language processing},
  author={Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, R{\'e}mi and Funtowicz, Morgan and others},
  journal={arXiv preprint arXiv:1910.03771},
  year={2019}
}

@article{floridi2020gpt,
  title={GPT-3: Its nature, scope, limits, and consequences},
  author={Floridi, Luciano and Chiriatti, Massimo},
  journal={Minds and Machines},
  volume={30},
  number={4},
  pages={681--694},
  year={2020},
  publisher={Springer}
}

@article{distilbert,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author={Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
  journal={arXiv preprint arXiv:1910.01108},
  year={2019}
}

@article{polino2018model,
  title={Model compression via distillation and quantization},
  author={Polino, Antonio and Pascanu, Razvan and Alistarh, Dan},
  journal={arXiv preprint arXiv:1802.05668},
  year={2018}
}

@inproceedings{mullapudi2019online,
  title={Online model distillation for efficient video inference},
  author={Mullapudi, Ravi Teja and Chen, Steven and Zhang, Keyi and Ramanan, Deva and Fatahalian, Kayvon},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3573--3582},
  year={2019}
}

@inproceedings{qiu2014ensemble,
  title={Ensemble deep learning for regression and time series forecasting},
  author={Qiu, Xueheng and Zhang, Le and Ren, Ye and Suganthan, Ponnuthurai N and Amaratunga, Gehan},
  booktitle={2014 IEEE symposium on computational intelligence in ensemble learning (CIEL)},
  pages={1--6},
  year={2014},
  organization={IEEE}
}


@misc{azure-spot,
	howpublished = {\url{https://azure.microsoft.com/en-in/products/virtual-machines/spot/}},
	title = {{Microsoft Azure Spot VMs}}}

@misc{aws-spot,
	howpublished = {\url{ https://aws.amazon.com/ec2/spot/}},
	title = {{Amazon Web Services Spot VMs}}}

@inproceedings{gupta2020deeprecsys,
  title={Deeprecsys: A system for optimizing end-to-end at-scale neural recommendation inference},
  author={Gupta, Udit and Hsia, Samuel and Saraph, Vikram and Wang, Xiaodong and Reagen, Brandon and Wei, Gu-Yeon and Lee, Hsien-Hsin S and Brooks, David and Wu, Carole-Jean},
  booktitle={2020 ACM/IEEE 47th Annual International Symposium on Computer Architecture (ISCA)},
  pages={982--995},
  year={2020},
  organization={IEEE}
}

@article{liu2014effects,
  title={The effects of interactive latency on exploratory visual analysis},
  author={Liu, Zhicheng and Heer, Jeffrey},
  journal={IEEE transactions on visualization and computer graphics},
  volume={20},
  number={12},
  pages={2122--2131},
  year={2014},
  publisher={IEEE}
}

@misc{azure-pricing,
	howpublished = {\url{https://azure.microsoft.com/en-in/pricing/details/virtual-machines/linux/}},
	title = {{Azure VM Pricing}}}

@article{wang2019language,
  title={Language models with transformers},
  author={Wang, Chenguang and Li, Mu and Smola, Alexander J},
  journal={arXiv preprint arXiv:1904.09408},
  year={2019}
}

@article{wang2019language1,
  title={Language models with transformers},
  author={Wang, Chenguang and Li, Mu and Smola, Alexander J},
  journal={arXiv preprint arXiv:1904.09408},
  year={2019}
}

@article{mark,
  title={Enabling cost-effective, slo-aware machine learning inference serving on public cloud},
  author={Zhang, Chengliang and Yu, Minchen and Wang, Wei and Yan, Feng},
  journal={IEEE Transactions on Cloud Computing},
  volume={10},
  number={3},
  pages={1765--1779},
  year={2020},
  publisher={IEEE}
}

@inproceedings{aiops2024qiu,
  author  = {Qiu, Haoran and Mao, Weichao and Patke, Archit and Cui, Shengkun and Jha, Saurabh and Wang, Chen and Franke, Hubertus and Kalbarczyk, Zbigniew T. and Ba\c{s}ar, Tamer and Iyer, Ravishankar K.},
  title   = {{Efficient Interactive LLM Serving with Proxy Model-based Sequence Length Prediction}},
  year    = {2024},
  booktitle = {The 5th International Workshop on Cloud Intelligence / AIOps at ASPLOS 2024},
}

@inproceedings {qiu2024muserve,
  title = {{Power-aware Deep Learning Model Serving with $\mu$-Serve}},
  author = {Haoran Qiu and Weichao Mao and Archit Patke and Shengkun Cui and Saurabh Jha and Chen Wang and Hubertus Franke and Zbigniew Kalbarczyk and Tamer Ba{\c s}ar and Ravishankar K. Iyer},
  booktitle = {USENIX Annual Technical Conference (USENIX ATC)},
  year = {2024},
}

@inproceedings{resnet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{vgg,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}

@inproceedings{regnet,
  title={RegNet: Multimodal sensor registration using deep neural networks},
  author={Schneider, Nick and Piewak, Florian and Stiller, Christoph and Franke, Uwe},
  booktitle={2017 IEEE intelligent vehicles symposium (IV)},
  pages={1803--1810},
  year={2017},
  organization={IEEE}
}

@inproceedings{resnext,
  title={Aggregated residual transformations for deep neural networks},
  author={Xie, Saining and Girshick, Ross and Doll{\'a}r, Piotr and Tu, Zhuowen and He, Kaiming},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1492--1500},
  year={2017}
}

@article{wide-resnet,
  title={Wide residual networks},
  author={Zagoruyko, Sergey and Komodakis, Nikos},
  journal={arXiv preprint arXiv:1605.07146},
  year={2016}
}

@article{roberta,
  title={{Roberta: A robustly optimized bert pretraining approach}},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}

@article{electra,
  title={{Electra: Pre-training text encoders as discriminators rather than generators}},
  author={Clark, Kevin and Luong, Minh-Thang and Le, Quoc V and Manning, Christopher D},
  journal={arXiv preprint arXiv:2003.10555},
  year={2020}
}

@inproceedings{xlm-roberta,
  title={Unsupervised Cross-lingual Representation Learning at Scale},
  author={Alexis Conneau and Kartikay Khandelwal and Naman Goyal and Vishrav Chaudhary and Guillaume Wenzek and Francisco Guzm{\'a}n and Edouard Grave and Myle Ott and Luke Zettlemoyer and Veselin Stoyanov},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  year={2019}
}

@article{xlnet,
  title={Xlnet: Generalized autoregressive pretraining for language understanding},
  author={Yang, Zhilin and Dai, Zihang and Yang, Yiming and Carbonell, Jaime and Salakhutdinov, Russ R and Le, Quoc V},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{albert,
  title={Albert: A lite bert for self-supervised learning of language representations},
  author={Lan, Zhenzhong and Chen, Mingda and Goodman, Sebastian and Gimpel, Kevin and Sharma, Piyush and Soricut, Radu},
  journal={arXiv preprint arXiv:1909.11942},
  year={2019}
}

@article{funnel-trans,
  title={{Funnel-transformer: Filtering out sequential redundancy for efficient language processing}},
  author={Dai, Zihang and Lai, Guokun and Yang, Yiming and Le, Quoc},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={4271--4282},
  year={2020}
}

@article{deberta,
  title={Deberta: Decoding-enhanced bert with disentangled attention},
  author={He, Pengcheng and Liu, Xiaodong and Gao, Jianfeng and Chen, Weizhu},
  journal={arXiv preprint arXiv:2006.03654},
  year={2020}
}

@inproceedings{kaimingrectifier,
    author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},  
    booktitle={ICCV},   
    title={{Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification}},   
    year={2015},  
    volume={},  
    number={},  
    pages={1026-1034},  
    doi={10.1109/ICCV.2015.123}
}

@inproceedings{attentionpaper,
    author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
    booktitle = {Advances in Neural Information Processing Systems},
    editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
    pages = {},
    publisher = {Curran Associates, Inc.},
    title = {{Attention is All you Need}},
    url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
    volume = {30},
    year = {2017}
}

@misc{self:attn:on2:memory,
      title={Self-attention Does Not Need $O(n^2)$ Memory}, 
      author={Markus N. Rabe and Charles Staats},
      year={2022},
      eprint={2112.05682},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{flashattention,
    title={{Flashattention: Fast and memory-efficient exact attention with io-awareness}},
    author={Dao, Tri and Fu, Dan and Ermon, Stefano and Rudra, Atri and R{\'e}, Christopher},
    booktitle={NeurIPS},
    volume={35},
    year={2022}
}

@misc{flashattention2,
    title={{FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning}},
    author={Tri Dao},
    year={2023},
    eprint={2307.08691},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}


@misc{efficiently-scaling-transformer-inference,
      title={Efficiently Scaling Transformer Inference}, 
      author={Reiner Pope and Sholto Douglas and Aakanksha Chowdhery and Jacob Devlin and James Bradbury and Anselm Levskaya and Jonathan Heek and Kefan Xiao and Shivani Agrawal and Jeff Dean},
      year={2022},
      eprint={2211.05102},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{lveval,
  title={Lv-eval: A balanced long-context benchmark with 5 length levels up to 256k},
  author={Yuan, Tao and Ning, Xuefei and Zhou, Dong and Yang, Zhijie and Li, Shiyao and Zhuang, Minghui and Tan, Zheyue and Yao, Zhuyu and Lin, Dahua and Li, Boxun and others},
  journal={arXiv preprint arXiv:2402.05136},
  year={2024}
}

@article{leval,
  title={L-eval: Instituting standardized evaluation for long context language models},
  author={An, Chenxin and Gong, Shansan and Zhong, Ming and Zhao, Xingjian and Li, Mukai and Zhang, Jun and Kong, Lingpeng and Qiu, Xipeng},
  journal={arXiv preprint arXiv:2307.11088},
  year={2023}
}

@misc{xformers,
    howpublished = {\url{https://facebookresearch.github.io/xformers/components/ops.html}},
    title = {{xFormers optimized operators}}
}

@misc{fastserve,
      title={{Fast Distributed Inference Serving for Large Language Models}},
      author={Bingyang Wu and Yinmin Zhong and Zili Zhang and Gang Huang and Xuanzhe Liu and Xin Jin},
      year={2023},
      eprint={2305.05920},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{retnet,
      title={{Retentive Network: A Successor to Transformer for Large Language Models}} ,
      author={Yutao Sun and Li Dong and Shaohan Huang and Shuming Ma and Yuqing Xia and Jilong Xue and Jianyong Wang and Furu Wei},
      year={2023},
      eprint={2307.08621},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{largescalemoe,
      title={{Efficient Large Scale Language Modeling with Mixtures of Experts}},
      author={Mikel Artetxe and Shruti Bhosale and Naman Goyal and Todor Mihaylov and Myle Ott and Sam Shleifer and Xi Victoria Lin and Jingfei Du and Srinivasan Iyer and Ramakanth Pasunuru and Giri Anantharaman and Xian Li and Shuohui Chen and Halil Akin and Mandeep Baines and Louis Martin and Xing Zhou and Punit Singh Koura and Brian O'Horo and Jeff Wang and Luke Zettlemoyer and Mona Diab and Zornitsa Kozareva and Ves Stoyanov},
      year={2022},
      eprint={2112.10684},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{multiqueryattention,
      title={Fast Transformer Decoding: One Write-Head is All You Need}, 
      author={Noam Shazeer},
      year={2019},
      eprint={1911.02150},
      archivePrefix={arXiv},
      primaryClass={cs.NE}
}

@misc{ray,
    title = {{Apache Ray}},
    author = {Apache Foundation},
    howpublished = {\url{https://docs.ray.io/en/latest/index.html}},
}

@misc{zmq,
    title = {{ZeroMQ}},
    howpublished = {\url{https://zeromq.org/}},
}

@misc{tensorrtllm:github,
    title = {{TensorRT-LLM: A TensorRT Toolbox for Optimized Large Language Model Inference}},
    howpublished = {\url{https://github.com/NVIDIA/TensorRT-LLM}},
}

@misc{lightllm:github,
    title = {{LightLLM: A Light and Fast Inference Service for LLM}},
    howpublished = {\url{https://github.com/ModelTC/lightllm}},
}

@misc{fastertransformer,
    title = {{Faster Transformer}},
    howpublished = {\url{https://github.com/NVIDIA/FasterTransformer}},
}

@misc{multinodeinferenceblog,
    title = {{Using NVIDIA's AI/ML Frameworks for Generative AI on VMware vSphere}},
    howpublished = {\url{https://core.vmware.com/blog/using-nvidias-aiml-frameworks-generative-ai-vmware-vsphere}},
}

@misc{largecontextlength,
    howpublished = {\url{https://blog.gopenai.com/how-to-speed-up-llms-and-use-100k-context-window-all-tricks-in-one-place-ffd40577b4c}},
    title = {{The Secret Sauce behind 100K context window in LLMs: All tricks in one place}}
}

@inproceedings{tritonpaper,
    author = {Tillet, Philippe and Kung, H. T. and Cox, David},
    title = {{Triton: An Intermediate Language and Compiler for Tiled Neural Network Computations}},
    year = {2019},
    isbn = {9781450367196},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3315508.3329973},
    doi = {10.1145/3315508.3329973},
    abstract = {XXX.},
    booktitle = {Proceedings of the 3rd ACM SIGPLAN International Workshop on Machine Learning and Programming Languages},
    pages = {10–19},
    numpages = {10},
    keywords = {compiler, neural networks, GPU},
    location = {Phoenix, AZ, USA},
    series = {MAPL 2019}
}

@inproceedings{varuna,
  title={Varuna: scalable, low-cost training of massive deep learning models},
  author={Athlur, Sanjith and Saran, Nitika and Sivathanu, Muthian and Ramjee, Ramachandran and Kwatra, Nipun},
  booktitle={Proceedings of the Seventeenth European Conference on Computer Systems},
  pages={472--487},
  year={2022}
}

@inproceedings{pipedream,
	title={PipeDream: generalized pipeline parallelism for DNN training},
	author={Narayanan, Deepak and Harlap, Aaron and Phanishayee, Amar and Seshadri, Vivek and Devanur, Nikhil R and Ganger, Gregory R and Gibbons, Phillip B and Zaharia, Matei},
	booktitle={Proceedings of the 27th ACM Symposium on Operating Systems Principles},
	pages={1--15},
	year={2019}
}

@article{gpipe,
  title={Gpipe: Efficient training of giant neural networks using pipeline parallelism},
  author={Huang, Yanping and Cheng, Youlong and Bapna, Ankur and Firat, Orhan and Chen, Dehao and Chen, Mia and Lee, HyoukJoong and Ngiam, Jiquan and Le, Quoc V and Wu, Yonghui and others},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{gpt3-brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}
@article{chowdhery2022Palm,
  author       = {Aakanksha Chowdhery and
                  Sharan Narang and
                  Jacob Devlin and
                  Maarten Bosma and
                  Gaurav Mishra and
                  Adam Roberts and
                  Paul Barham and
                  Hyung Won Chung and
                  Charles Sutton and
                  Sebastian Gehrmann and
                  Parker Schuh and
                  Kensen Shi and
                  Sasha Tsvyashchenko and
                  Joshua Maynez and
                  Abhishek Rao and
                  Parker Barnes and
                  Yi Tay and
                  Noam Shazeer and
                  Vinodkumar Prabhakaran and
                  Emily Reif and
                  Nan Du and
                  Ben Hutchinson and
                  Reiner Pope and
                  James Bradbury and
                  Jacob Austin and
                  Michael Isard and
                  Guy Gur{-}Ari and
                  Pengcheng Yin and
                  Toju Duke and
                  Anselm Levskaya and
                  Sanjay Ghemawat and
                  Sunipa Dev and
                  Henryk Michalewski and
                  Xavier Garcia and
                  Vedant Misra and
                  Kevin Robinson and
                  Liam Fedus and
                  Denny Zhou and
                  Daphne Ippolito and
                  David Luan and
                  Hyeontaek Lim and
                  Barret Zoph and
                  Alexander Spiridonov and
                  Ryan Sepassi and
                  David Dohan and
                  Shivani Agrawal and
                  Mark Omernick and
                  Andrew M. Dai and
                  Thanumalayan Sankaranarayana Pillai and
                  Marie Pellat and
                  Aitor Lewkowycz and
                  Erica Moreira and
                  Rewon Child and
                  Oleksandr Polozov and
                  Katherine Lee and
                  Zongwei Zhou and
                  Xuezhi Wang and
                  Brennan Saeta and
                  Mark Diaz and
                  Orhan Firat and
                  Michele Catasta and
                  Jason Wei and
                  Kathy Meier{-}Hellstern and
                  Douglas Eck and
                  Jeff Dean and
                  Slav Petrov and
                  Noah Fiedel},
  title        = {PaLM: Scaling Language Modeling with Pathways},
  journal      = {CoRR},
  volume       = {abs/2204.02311},
  year         = {2022},
  url          = {https://doi.org/10.48550/arXiv.2204.02311},
  doi          = {10.48550/arXiv.2204.02311},
  eprinttype    = {arXiv},
  eprint       = {2204.02311},
  timestamp    = {Wed, 16 Aug 2023 16:10:28 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2204-02311.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{kaplan2020scalinglaws,
  author       = {Jared Kaplan and
                  Sam McCandlish and
                  Tom Henighan and
                  Tom B. Brown and
                  Benjamin Chess and
                  Rewon Child and
                  Scott Gray and
                  Alec Radford and
                  Jeffrey Wu and
                  Dario Amodei},
  title        = {Scaling Laws for Neural Language Models},
  journal      = {CoRR},
  volume       = {abs/2001.08361},
  year         = {2020},
  url          = {https://arxiv.org/abs/2001.08361},
  eprinttype    = {arXiv},
  eprint       = {2001.08361},
  timestamp    = {Wed, 03 Jun 2020 10:55:13 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2001-08361.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{wei2022emergent,
  author       = {Jason Wei and
                  Yi Tay and
                  Rishi Bommasani and
                  Colin Raffel and
                  Barret Zoph and
                  Sebastian Borgeaud and
                  Dani Yogatama and
                  Maarten Bosma and
                  Denny Zhou and
                  Donald Metzler and
                  Ed H. Chi and
                  Tatsunori Hashimoto and
                  Oriol Vinyals and
                  Percy Liang and
                  Jeff Dean and
                  William Fedus},
  title        = {Emergent Abilities of Large Language Models},
  journal      = {Trans. Mach. Learn. Res.},
  volume       = {2022},
  year         = {2022},
  url          = {https://openreview.net/forum?id=yzkSU5zdwD},
  timestamp    = {Fri, 19 May 2023 11:20:41 +0200},
  biburl       = {https://dblp.org/rec/journals/tmlr/WeiTBRZBYBZMCHVLDF22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{openai2022gpt4techreport,
  author       = {OpenAI},
  title        = {{GPT-4} Technical Report},
  journal      = {CoRR},
  volume       = {abs/2303.08774},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2303.08774},
  doi          = {10.48550/arXiv.2303.08774},
  eprinttype    = {arXiv},
  eprint       = {2303.08774},
  timestamp    = {Mon, 20 Mar 2023 15:23:19 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2303-08774.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@misc{chatgpt,
  title = {ChatGPT},
  howpublished = {{https://chat.openai.com}},
}
@misc{claudeai,
  title = {Anthropic Claude},
  howpublished = {\url{https://claude.ai}},
}
@misc{characterai,
  title = {Character AI},
  howpublished = {\url{https://character.ai}},
}
@misc{bingai,
  title = {Bing AI},
  howpublished = {\url{https://www.bing.com/chat}},
}
@misc{nccl,
  title = {NVIDIA Collective Communications Library (NCCL)},
  howpublished = {\url{https://developer.nvidia.com/nccl}},
}

@misc{nvidiadgx,
  title = {NVIDIA DGX Platform},
  howpublished = {\url{https://www.nvidia.com/en-us/data-center/dgx-platform/}},
}

@misc{komoai,
  title = {Komo},
  howpublished = {\url{https://komo.ai/}},
}
@misc{youdotcom,
  title = {You.com},
  howpublished = {\url{https://you.com/}},
}
@misc{perplexityai,
  title = {Perplexity AI},
  howpublished = {\url{https://www.perplexity.ai/}},
}
@misc{bard,
  title = {Google Bard},
  howpublished = {\url{https://bard.google.com}},
}
@misc{githubcopilot,
  title = {Github Copilot},
  howpublished = {\url{https://github.com/features/copilot}},
}
@misc{microsoftcopilot,
  title = {Microsoft Copilot},
  howpublished = {\url{https://www.microsoft.com/en-us/microsoft-copilot}},
}
@misc{googleduetai,
  title = {Google Duet AI},
  howpublished = {\url{https://workspace.google.com/solutions/ai/}},
}
@misc{arxiv,
  title = {arXiv.org e-Print archive},
  howpublished = {\url{https://arxiv.org/}},
}
@misc{replitghostwriter,
  title = {Replit Ghostwriter},
  howpublished = {\url{https://replit.com/site/ghostwriter}},
}

@misc{amazoncodewhisperer,
  title = {Amazon CodeWhisperer},
  howpublished = {\url{https://aws.amazon.com/codewhisperer/}},
}

@misc{tile-quantization,
  title = {Matrix Multiplication Background User's Guide},
  howpublished = {\url{https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html}},
}

@misc{nanogpt,
  title = {nanoGPT},
  howpublished = {\url{https://github.com/karpathy/nanoGPT}},
}


@misc{llama4,
  title = {{The Llama 4 herd: The beginning of a new era of natively multimodal AI innovation}},
  author = {Meta},
  howpublished = {\url{https://ai.meta.com/blog/llama-4-multimodal-intelligence}},
}


@misc{touvron2023llama,
      title={{Llama 2: Open Foundation and Fine-Tuned Chat Models}}, 
      author={Hugo Touvron and Louis Martin and Kevin Stone and Peter Albert and Amjad Almahairi and Yasmine Babaei and Nikolay Bashlykov and Soumya Batra and Prajjwal Bhargava and Shruti Bhosale and Dan Bikel and Lukas Blecher and Cristian Canton Ferrer and Moya Chen and Guillem Cucurull and David Esiobu and Jude Fernandes and Jeremy Fu and Wenyin Fu and Brian Fuller and Cynthia Gao and Vedanuj Goswami and Naman Goyal and Anthony Hartshorn and Saghar Hosseini and Rui Hou and Hakan Inan and Marcin Kardas and Viktor Kerkez and Madian Khabsa and Isabel Kloumann and Artem Korenev and Punit Singh Koura and Marie-Anne Lachaux and Thibaut Lavril and Jenya Lee and Diana Liskovich and Yinghai Lu and Yuning Mao and Xavier Martinet and Todor Mihaylov and Pushkar Mishra and Igor Molybog and Yixin Nie and Andrew Poulton and Jeremy Reizenstein and Rashi Rungta and Kalyan Saladi and Alan Schelten and Ruan Silva and Eric Michael Smith and Ranjan Subramanian and Xiaoqing Ellen Tan and Binh Tang and Ross Taylor and Adina Williams and Jian Xiang Kuan and Puxin Xu and Zheng Yan and Iliyan Zarov and Yuchen Zhang and Angela Fan and Melanie Kambadur and Sharan Narang and Aurelien Rodriguez and Robert Stojnic and Sergey Edunov and Thomas Scialom},
      year={2023},
      eprint={2307.09288},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{almazrouei2023falcon,
      title={The Falcon Series of Open Language Models}, 
      author={Ebtesam Almazrouei and Hamza Alobeidli and Abdulaziz Alshamsi and Alessandro Cappelli and Ruxandra Cojocaru and Mérouane Debbah and Étienne Goffinet and Daniel Hesslow and Julien Launay and Quentin Malartic and Daniele Mazzotta and Badreddine Noune and Baptiste Pannier and Guilherme Penedo},
      year={2023},
      eprint={2311.16867},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{patel2023polcapoweroversubscriptionllm,
      title={{POLCA: Power Oversubscription in LLM Cloud Providers}}, 
      author={Pratyush Patel and Esha Choukse and Chaojie Zhang and Íñigo Goiri and Brijesh Warrier and Nithish Mahalingam and Ricardo Bianchini},
      year={2023},
      eprint={2308.12908},
      archivePrefix={arXiv},
      primaryClass={cs.DC},
      url={https://arxiv.org/abs/2308.12908}, 
}

@inproceedings{patel2023splitwise,
      title={{Splitwise: Efficient generative LLM inference using phase splitting}}, 
      author={Pratyush Patel and Esha Choukse and Chaojie Zhang and Íñigo Goiri and Aashaka Shah and Saeed Maleki and Ricardo Bianchini},
      year={2024},
      booktitle={ISCA},
}

@misc{etalon,
      title={{Etalon: Holistic Performance Evaluation Framework for LLM Inference Systems}}, 
      author={Amey Agrawal and Anmol Agarwal and Nitin Kedia and Jayashree Mohan and Souvik Kundu and Nipun Kwatra and Ramachandran Ramjee and Alexey Tumanov},
      year={2024},
      eprint={2407.07000},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2407.07000}, 
}

@inproceedings{cohan-etal-2018-discourse,
  title = "A Discourse-Aware Attention Model for Abstractive Summarization of Long Documents",
  author = "Cohan, Arman  and
    Dernoncourt, Franck  and
    Kim, Doo Soon  and
    Bui, Trung  and
    Kim, Seokhwan  and
    Chang, Walter  and
    Goharian, Nazli",
  booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)",
  month = jun,
  year = "2018",
  address = "New Orleans, Louisiana",
  publisher = "Association for Computational Linguistics",
  url = "https://aclanthology.org/N18-2097",
  doi = "10.18653/v1/N18-2097",
  pages = "615--621",
}

@misc{wang2023openchat,
      title={{OpenChat: Advancing Open-source Language Models with Mixed-Quality Data}}, 
      author={Guan Wang and Sijie Cheng and Xianyuan Zhan and Xiangang Li and Sen Song and Yang Liu},
      year={2023},
      eprint={2309.11235},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{zheng2023lmsyschat1m,
      title={{LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset}}, 
      author={Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Tianle Li and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zhuohan Li and Zi Lin and Eric. P Xing and Joseph E. Gonzalez and Ion Stoica and Hao Zhang},
      year={2023},
      eprint={2309.11998},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{gpt3,
  title = {OpenAI GPT-3: Understanding the Architecture},
  howpublished = {\url{https://www.theaidream.com/post/openai-gpt-3-understanding-the-architecture}},
}

@misc{hftgi,
  title = {Text Generation Inference},
  howpublished = {\url{https://huggingface.co/text-generation-inference}},
}

@misc{deepspeed-multigpu,
  title = {DeepSpeed Inference: Multi-GPU inference with customized inference kernels and quantization support},
  howpublished = {\url{https://www.deepspeed.ai/2021/03/15/inference-kernel-optimization.html}},
}

@misc{qlora,
      title={{QLoRA: Efficient Finetuning of Quantized LLMs}}, 
      author={Tim Dettmers and Artidoro Pagnoni and Ari Holtzman and Luke Zettlemoyer},
      year={2023},
      eprint={2305.14314},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{gptq,
    title={{GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers}}, 
    author={Elias Frantar and Saleh Ashkboos and Torsten Hoefler and Dan Alistarh},
    year={2023},
    eprint={2210.17323},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{smoothquant,
    title={{SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models}}, 
    author={Guangxuan Xiao and Ji Lin and Mickael Seznec and Hao Wu and Julien Demouth and Song Han},
    year={2023},
    eprint={2211.10438},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{llmint8,
      title={{LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale}}, 
      author={Tim Dettmers and Mike Lewis and Younes Belkada and Luke Zettlemoyer},
      year={2022},
      eprint={2208.07339},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{moedeployment,
    title={{Towards MoE Deployment: Mitigating Inefficiencies in Mixture-of-Expert (MoE) Inference}}, 
    author={Haiyang Huang and Newsha Ardalani and Anna Sun and Liu Ke and Hsien-Hsin S. Lee and Anjali Sridhar and Shruti Bhosale and Carole-Jean Wu and Benjamin Lee},
    year={2023},
    eprint={2303.06182},
    archivePrefix={arXiv},
    primaryClass={cs.DC}
}

@inproceedings {moeatc23,
    author = {Jiamin Li and Yimin Jiang and Yibo Zhu and Cong Wang and Hong Xu},
    title = {{Accelerating Distributed MoE Training and Inference with Lina}},
    booktitle = {USENIX ATC},
    year = {2023},
}

@inproceedings{coconetasplos,
    author = {Jangda, Abhinav and Huang, Jun and Liu, Guodong and Sabet, Amir Hossein Nodehi and Maleki, Saeed and Miao, Youshan and Musuvathi, Madanlal and Mytkowicz, Todd and Saarikivi, Olli},
    title = {{Breaking the Computation and Communication Abstraction Barrier in Distributed Machine Learning Workloads}},
    year = {2022},
    booktitle = {ASPLOS},
}

@inproceedings{googleoverlap,
    author = {Wang, Shibo and Wei, Jinliang and Sabne, Amit and Davis, Andy and Ilbeyi, Berkin and Hechtman, Blake and Chen, Dehao and Murthy, Karthik Srinivasa and Maggioni, Marcello and Zhang, Qiao and Kumar, Sameer and Guo, Tongfei and Xu, Yuanzhong and Zhou, Zongwei},
    title = {{Overlap Communication with Dependent Computation via Decomposition in Large Deep Learning Models}},
    year = {2023},
    booktitle = {ASPLOS},
}


@inproceedings{batchmakereurosys,
    author = {Gao, Pin and Yu, Lingfan and Wu, Yongwei and Li, Jinyang},
    title = {Low Latency RNN Inference with Cellular Batching},
    year = {2018},
    booktitle = {EuroSys},
}

@misc{tensorflowserving,
      title={{TensorFlow-Serving: Flexible, High-Performance ML Serving}}, 
      author={Christopher Olston and Noah Fiedel and Kiril Gorovoy and Jeremiah Harmsen and Li Lao and Fangwei Li and Vinu Rajashekhar and Sukriti Ramesh and Jordan Soyke},
      year={2017},
      eprint={1712.06139},
      archivePrefix={arXiv},
      primaryClass={cs.DC}
}

@inproceedings{vllmsosp,
    author = {Kwon, Woosuk and Li, Zhuohan and Zhuang, Siyuan and Sheng, Ying and Zheng, Lianmin and Yu, Cody Hao and Gonzalez, Joseph and Zhang, Hao and Stoica, Ion},
    title = {{Efficient Memory Management for Large Language Model Serving with PagedAttention}},
    year = {2023},
    booktitle = {SOSP}
}

@InProceedings{lightseq,
    title = {{LightSeq: A High Performance Inference Library for Transformers}},
    author = "Wang, Xiaohui and Xiong, Ying and Wei, Yang and Wang, Mingxuan and Li, Lei",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Industry Papers (NAACL-HLT)",
    month = jun,
    year = "2021",
    publisher = "Association for Computational Linguistics",
    pages = "113--120",
}

@misc{longformer,
      title={Longformer: The Long-Document Transformer}, 
      author={Iz Beltagy and Matthew E. Peters and Arman Cohan},
      year={2020},
      eprint={2004.05150},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{jiang2023mistral,
  title={Mistral 7B},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and others},
  journal={arXiv preprint arXiv:2310.06825},
  year={2023}
}

@misc{yi,
    howpublished = {\url{https://huggingface.co/01-ai/Yi-34B-200K}},
    title = {{Yi series of large language models trained from scratch by developers at 01.AI.}}
}


@inproceedings{arachneosdi,
    author = {Henry Qin and Qian Li and Jacqueline Speiser and Peter Kraft and John Ousterhout},
    title = {{Arachne: Core-Aware Thread Management}},
    booktitle = {OSDI},
    year = {2018},
}

BibTeX
@inproceedings{shenango,
    author = {Ousterhout, Amy and Fried, Joshua and Behrens, Jonathan and Belay, Adam and Balakrishnan, Hari},
    title = {Shenango: Achieving High CPU Efficiency for Latency-Sensitive Datacenter Workloads},
    year = {2019},
    booktitle = {NSDI}
}

@inproceedings {ingens,
    author = {Youngjin Kwon and Hangchen Yu and Simon Peter and Christopher J. Rossbach and Emmett Witchel},
    title = {{Coordinated and Efficient Huge Page Management with Ingens}},
    booktitle = {OSDI},
    year = {2016},
}

@inproceedings{hawkeye,
    author = {Panwar, Ashish and Bansal, Sorav and Gopinath, K.},
    title = {{HawkEye: Efficient Fine-Grained OS Support for Huge Pages}},
    year = {2019},
    booktitle = {ASPLOS},
}

@misc{distserve2024,
      title={{DistServe: Disaggregating Prefill and Decoding for Goodput-optimized Large Language Model Serving}}, 
      author={Yinmin Zhong and Shengyu Liu and Junda Chen and Jianbo Hu and Yibo Zhu and Xuanzhe Liu and Xin Jin and Hao Zhang},
      year={2024},
      eprint={2401.09670},
      archivePrefix={arXiv},
      primaryClass={cs.DC}
}

@misc{gelu2023,
      title={Gaussian Error Linear Units (GELUs)}, 
      author={Dan Hendrycks and Kevin Gimpel},
      year={2023},
      eprint={1606.08415},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{relu2019,
      title={Deep Learning using Rectified Linear Units (ReLU)}, 
      author={Abien Fred Agarap},
      year={2019},
      eprint={1803.08375},
      archivePrefix={arXiv},
      primaryClass={cs.NE}
}

@misc{splitfuse2024,
      title={{DeepSpeed-FastGen: High-throughput Text Generation for LLMs via MII and DeepSpeed-Inference}}, 
      author={Connor Holmes and Masahiro Tanaka and Michael Wyatt and Ammar Ahmad Awan and Jeff Rasley and Samyam Rajbhandari and Reza Yazdani Aminabadi and Heyang Qin and Arash Bakhtiari and Lev Kurilenko and Yuxiong He},
      year={2024},
      eprint={2401.08671},
      archivePrefix={arXiv},
      primaryClass={cs.PF}
}

@article{tetriinfer,
      title={{Inference without Interference: Disaggregate LLM Inference for Mixed Downstream Workloads}},
      author={Hu, Cunchen and Huang, Heyang and Xu, Liangliang and Chen, Xusheng and Xu, Jiang and Chen, Shuang and Feng, Hao and Wang, Chenxi and Wang, Sa and Bao, Yungang and others},
      journal={arXiv preprint arXiv:2401.11181},
      year={2024}
}

@article{sheng2023fairness,
    title={{Fairness in Serving Large Language Models}},
      author={Sheng, Ying and Cao, Shiyi and Li, Dacheng and Zhu, Banghua and Li, Zhuohan and Zhuo, Danyang and Gonzalez, Joseph E and Stoica, Ion},
      journal={arXiv preprint arXiv:2401.00588},
      year={2023}
}

@article{abhyankar2024apiserve,
      title={{APIServe: Efficient API Support for Large-Language Model Inferencing}},
      author={Abhyankar, Reyna and He, Zijian and Srivatsa, Vikranth and Zhang, Hao and Zhang, Yiying},
      journal={arXiv preprint arXiv:2402.01869},
      year={2024}
}

@misc{liu2023ring,
      title={{Ring Attention with Blockwise Transformers for Near-Infinite Context}}, 
      author={Hao Liu and Matei Zaharia and Pieter Abbeel},
      year={2023},
      eprint={2310.01889},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.01889}, 
}

@article{brandon2023striped,
      title={{Striped attention: Faster ring attention for causal transformers}},
      author={Brandon, William and Nrusimha, Aniruddha and Qian, Kevin and Ankner, Zachary and Jin, Tian and Song, Zhiye and Ragan-Kelley, Jonathan},
      journal={arXiv preprint arXiv:2311.09431},
      year={2023}
}


@misc{mooncake,
      title={{Mooncake: A KVCache-centric Disaggregated Architecture for LLM Serving}}, 
      author={Ruoyu Qin and Zheming Li and Weiran He and Mingxing Zhang and Yongwei Wu and Weimin Zheng, Xinran Xu},
      year={2024},
      eprint={2407.00079},
      archivePrefix={arXiv},
      primaryClass={cs.DC},
      url={https://arxiv.org/abs/2407.00079}, 
}

@misc{gemini,
      title={{Gemini -- Long context}}, 
      author={Google},
      year={2024},
      url={https://ai.google.dev/gemini-api/docs/long-context}, 
}

@misc{magic,
      title={{100M Token Context Windows}}, 
      author={Magic},
      year={2024},
      url={https://magic.dev/blog/100m-token-context-windows}, 
}

@misc{h100,
    author = {{NVIDIA}},
    title = {{DGX H100: AI for Enterprise}},
    year = {2024},
    howpublished = {\url{https://www.nvidia.com/en-us/data-center/dgx-h100/}}
}

@misc{h100azure,
    author = {{Microsoft Azure}},
    title = {{ND-H100-v5 sizes series}},
    year = {2024},
    howpublished = {\url{https://learn.microsoft.com/en-us/azure/virtual-machines/sizes/gpu-accelerated/ndh100v5-series?tabs=sizenetwork}}
}

@misc{a100azure,
    author = {{Microsoft Azure}},
    title = {{NDm-A100-v4 sizes series}},
    year = {2024},
        howpublished = {\url{https://learn.microsoft.com/en-us/azure/virtual-machines/sizes/gpu-accelerated/ndma100v4-series?tabs=sizebasic}}
}



@inproceedings{turbotransformers,
  author       = {Jiarui Fang and
                  Yang Yu and
                  Chengduo Zhao and
                  Jie Zhou},
  title        = {{TurboTransformers: an efficient GPU serving system for transformer models}},
  booktitle    = {PPoPP},
  year         = {2021},
}


@article{vidur, 
    title={{Vidur: A Large-Scale Simulation Framework For LLM Inference}},
    author={Agrawal, Amey and Kedia, Nitin and Mohan, Jayashree and Panwar, Ashish  and Kwatra, Nipun and Gulavani, Bhargav S and Ramjee, Ramachandran and Tumanov, Alexey},
    journal={MLSys},
    year={2024}
}

@article{kang2024gear,
    title={{Gear: An efficient kv cache compression recipefor near-lossless generative inference of LLM}},
    author={Kang, Hao and Zhang, Qingru and Kundu, Souvik and Jeong, Geonhwa and Liu, Zaoxing and Krishna, Tushar and Zhao, Tuo},
    journal={arXiv preprint arXiv:2403.05527},
    year={2024}
}

@article{qiao2024vl,
    title={Vl-mamba: Exploring state space models for multimodal learning},
    author={Qiao, Yanyuan and Yu, Zheng and Guo, Longteng and Chen, Sihan and Zhao, Zijia and Sun, Mingzhen and Wu, Qi and Liu, Jing},
    journal={arXiv preprint arXiv:2403.13600},
    year={2024}
}

@misc{MSFTBERT,
    date-added = {2022-12-07 01:43:51 -0800},
    date-modified = {2022-12-07 01:43:51 -0800},
    howpublished = {\url{https://cloudblogs.microsoft.com/opensource/2020/01/21/microsoft-onnx-open-source-optimizations-transformer-inference-gpu-cpu/}},
    title = {{Microsoft open sources breakthrough optimizations for transformer inference on GPU and CPU}}
}

@misc{gpt3-api,
    date-added = {2022-12-07 01:43:51 -0800},
    date-modified = {2022-12-07 01:43:51 -0800},
    howpublished = {\url{https://medium.com/modern-nlp/estimating-gpt3-api-cost-50282f869ab8}},
    title = {{Estimating GPT3 API Cost}}
}

@misc{onnx-ms,
    date-added = {2022-12-07 01:43:51 -0800},
    date-modified = {2022-12-07 01:43:51 -0800},
    howpublished = {\url{https://onnxruntime.ai/about.html}},
    title = {{ONNX Runtime usage at Microsoft}}
}

@misc{distilled-deploy,
	date-added = {2022-12-07 01:43:51 -0800},
	date-modified = {2022-12-07 01:43:51 -0800},
	howpublished = {\url{https://medium.com/data-science-at-microsoft/model-compression-and-optimization-why-\\think-bigger-when-you-can-think-smaller-\\216ec096f68b}},
	title = {{Model compression and optimization: Why think bigger when you can think smaller?}}
}

@misc{batch-inference,
	date-added = {2022-12-07 01:43:51 -0800},
	date-modified = {2022-12-07 01:43:51 -0800},
	howpublished = {\url{https://mlinproduction.com/batch-inference-vs-online-inference/}},
	title = {{Batch Inference}}
}

@inproceedings{bert,
  author    = {Jacob Devlin and
               Ming{-}Wei Chang and
               Kenton Lee and
               Kristina Toutanova},
  title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
               Understanding},
  booktitle = {Proceedings of the 2019 Conference of the North American Chapter of
               the Association for Computational Linguistics: Human Language Technologies,
               {NAACL-HLT} 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long
               and Short Papers)},
  pages     = {4171--4186},
  publisher = {Association for Computational Linguistics},
  year      = {2019},
  url       = {https://doi.org/10.18653/v1/n19-1423},
  doi       = {10.18653/v1/n19-1423},
  timestamp = {Mon, 26 Sep 2022 12:21:55 +0200},
  biburl    = {https://dblp.org/rec/conf/naacl/DevlinCLT19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

 @misc{amex,
    date-added = {2022-12-07 01:43:51 -0800},
    date-modified = {2022-12-07 01:43:51 -0800},
    howpublished = {\url{https://blogs.nvidia.com/blog/2020/10/05/american-express-nvidia-ai/}},
    title = {{American Express Adopts NVIDIA AI to Help Prevent Fraud and Foil Cybercrime}}
}

@inproceedings{clipper,
    title={{Clipper: A Low-Latency Online Prediction Serving System}},
    author={Crankshaw, Daniel and Wang, Xin and Zhou, Guilio and Franklin, Michael J and Gonzalez, Joseph E and Stoica, Ion},
    booktitle={NSDI},
    year={2017}
}

@article{tirumala1999iperf,
  title={Iperf: The TCP/UDP bandwidth measurement tool},
  author={Tirumala, Ajay},
  journal={http://dast. nlanr. net/Projects/Iperf/},
  year={1999}
}

%%article{appendix,
%  title={Supplementary material for paper #334 (OSDI 23)},
%  author={Anonymous},
%  journal={},
%  year={2022}
%}

@article{ILSVRC15,
    author = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
    Title = {{ImageNet Large Scale Visual Recognition Challenge}},
    Year = {2015},
    journal   = {International Journal of Computer Vision (IJCV)},
    doi = {10.1007/s11263-015-0816-y},
    volume={115},
    number={3},
    pages={211-252}
}

@inproceedings{williams2018broadmnli,
   author = {Williams, Adina and Nangia, Nikita and Bowman, Samuel R.},
   title = {A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference},
   booktitle = {Proceedings of NAACL-HLT},
   year = 2018
 }

 @online{twitter-trace,
  author = {Twitter, Inc.},
  title = {ArchiveTeam JSON Download of Twitter Stream 2018-04},
  year = 2018,
  url = {https://archive.org/details/archiveteam-twitter-stream-2018-04},
  urldate = {2018-05-23}
}

@inproceedings{cocktail,
  title={Cocktail: A Multidimensional Optimization for Model Serving in Cloud},
  author={Gunasekaran, Jashwant Raj and Mishra, Cyan Subhra and Thinakaran, Prashanth and Sharma, Bikash and Kandemir, Mahmut Taylan and Das, Chita R},
  booktitle={19th USENIX Symposium on Networked Systems Design and Implementation (NSDI 22)},
  pages={1041--1057},
  year={2022}
}

@inproceedings{infaas,
  title={$\{$INFaaS$\}$: Automated Model-less Inference Serving},
  author={Romero, Francisco and Li, Qian and Yadwadkar, Neeraja J and Kozyrakis, Christos},
  booktitle={2021 USENIX Annual Technical Conference (USENIX ATC 21)},
  pages={397--411},
  year={2021}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@article{bbr,
  title={Bbr: Congestion-based congestion control: Measuring bottleneck bandwidth and round-trip propagation time},
  author={Cardwell, Neal and Cheng, Yuchung and Gunn, C Stephen and Yeganeh, Soheil Hassas and Jacobson, Van},
  journal={Queue},
  volume={14},
  number={5},
  pages={20--53},
  year={2016},
  publisher={ACM New York, NY, USA}
}

@inproceedings{clockwork,
  title={Serving $\{$DNNs$\}$ like Clockwork: Performance Predictability from the Bottom Up},
  author={Gujarati, Arpan and Karimi, Reza and Alzayat, Safya and Hao, Wei and Kaufmann, Antoine and Vigfusson, Ymir and Mace, Jonathan},
  booktitle={14th USENIX Symposium on Operating Systems Design and Implementation (OSDI 20)},
  pages={443--462},
  year={2020}
}

@inproceedings{swayam,
  title={Swayam: distributed autoscaling to meet slas of machine learning inference services with resource efficiency},
  author={Gujarati, Arpan and Elnikety, Sameh and He, Yuxiong and McKinley, Kathryn S and Brandenburg, Bj{\"o}rn B},
  booktitle={Proceedings of the 18th ACM/IFIP/USENIX middleware conference},
  pages={109--120},
  year={2017}
}

@misc{cocktail-repo,
	howpublished = {\url{https://github.com/jashwantraj92/cocktail}},
	title = {{Cocktail repository}}}

@misc{pytorch-version,
	howpublished = {\url{https://github.com/pytorch/pytorch/commit/8a1a93a}},
	title = {{Pytorch version 1.12.0a0+8a1a93a}}}

@misc{amp,
	howpublished = {\url{https://pytorch.org/docs/stable/amp.html}},
	title = {{Pytorch AMP}}}

@article{grpc,
  title={GRPC: A communication cooperation mechanism in distributed systems},
  author={Wang, Xingwei and Zhao, Hong and Zhu, Jiakeng},
  journal={ACM SIGOPS Operating Systems Review},
  volume={27},
  number={3},
  pages={75--86},
  year={1993},
  publisher={ACM New York, NY, USA}
}

@misc{triton,
	howpublished = {\url{https://developer.nvidia.com/nvidia-triton-inference-server}},
	title = {{NVIDIA Triton Inference Server}}}

@article{majority-voting,
  title={Dynamic weighted majority: An ensemble method for drifting concepts},
  author={Kolter, J Zico and Maloof, Marcus A},
  journal={The Journal of Machine Learning Research},
  volume={8},
  pages={2755--2790},
  year={2007},
  publisher={JMLR. org}
}

@inproceedings{weighted-averaging,
  title={Robust Bayesian linear classifier ensembles},
  author={Cerquides, Jes{\'u}s and M{\'a}ntaras, Ramon L{\'o}pez de},
  booktitle={European Conference on Machine Learning},
  pages={72--83},
  year={2005},
  organization={Springer}
}

@inproceedings{power-of-ensembles,
  title={The power of ensembles for active learning in image classification},
  author={Beluch, William H and Genewein, Tim and N{\"u}rnberger, Andreas and K{\"o}hler, Jan M},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={9368--9377},
  year={2018}
}

@article{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{spot-instances,
  title={Using burstable instances in the public cloud: Why, when and how?},
  author={Wang, Cheng and Urgaonkar, Bhuvan and Nasiriani, Neda and Kesidis, George},
  journal={Proceedings of the ACM on Measurement and Analysis of Computing Systems},
  volume={1},
  number={1},
  pages={1--28},
  year={2017},
  publisher={ACM New York, NY, USA}
}

@misc{docker,
	howpublished = {\url{https://www.docker.com/}},
	title = {{Docker}}}

@inproceedings{half-precision-exploiting,
  title={Exploiting half precision arithmetic in Nvidia GPUs},
  author={Ho, Nhut-Minh and Wong, Weng-Fai},
  booktitle={2017 IEEE High Performance Extreme Computing Conference (HPEC)},
  pages={1--7},
  year={2017},
  organization={IEEE}
}

@inproceedings{synergy,
  title={Looking Beyond $\{$GPUs$\}$ for $\{$DNN$\}$ Scheduling on $\{$Multi-Tenant$\}$ Clusters},
  author={Mohan, Jayashree and Phanishayee, Amar and Kulkarni, Janardhan and Chidambaram, Vijay},
  booktitle={16th USENIX Symposium on Operating Systems Design and Implementation (OSDI 22)},
  pages={579--596},
  year={2022}
}

@misc{triton-batch,
	howpublished = {\url{https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user\_guide/model\_configuration.html#dynamic-batcher}},
	title = {{NVIDIA Triton Dynamic Batching}}}

@inproceedings{efficientnet,
  title={Efficientnet: Rethinking model scaling for convolutional neural networks},
  author={Tan, Mingxing and Le, Quoc},
  booktitle={International conference on machine learning},
  pages={6105--6114},
  year={2019},
  organization={PMLR}
}

@inproceedings{imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}

@inproceedings{gujarati2020serving,
  title={Serving $\{$DNNs$\}$ like Clockwork: Performance Predictability from the Bottom Up},
  author={Gujarati, Arpan and Karimi, Reza and Alzayat, Safya and Hao, Wei and Kaufmann, Antoine and Vigfusson, Ymir and Mace, Jonathan},
  booktitle={14th USENIX Symposium on Operating Systems Design and Implementation (OSDI 20)},
  pages={443--462},
  year={2020}
}

@inproceedings{hazelwood2018applied,
  title={Applied machine learning at facebook: A datacenter infrastructure perspective},
  author={Hazelwood, Kim and Bird, Sarah and Brooks, David and Chintala, Soumith and Diril, Utku and Dzhulgakov, Dmytro and Fawzy, Mohamed and Jia, Bill and Jia, Yangqing and Kalro, Aditya and others},
  booktitle={2018 IEEE International Symposium on High Performance Computer Architecture (HPCA)},
  pages={620--629},
  year={2018},
  organization={IEEE}
}



@misc{google-model-ensembles-faster,
	howpublished = {\url{https://ai.googleblog.com/2021/11/model-ensembles-are-faster-than-you.html}},
	title = {{Model ensembles are faster than you think}}}

@misc{amazon-sagemaker,
	howpublished = {\url{https://aws.amazon.com/sagemaker/}},
	title = {{Amazon SageMaker}}}

@misc{azure-mlaas,
	howpublished = {\url{https://azure.microsoft.com/en-us/products/machine-learning/#product-overview}},
	title = {{Azure Machine Learning as a service}}}

 @inproceedings{senior2014improving,
  title={Improving DNN speaker independence with i-vector inputs},
  author={Senior, Andrew and Lopez-Moreno, Ignacio},
  booktitle={2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={225--229},
  year={2014},
  organization={IEEE}
}

@inproceedings{bartlett2005recognizing,
  title={Recognizing facial expression: machine learning and application to spontaneous behavior},
  author={Bartlett, Marian Stewart and Littlewort, Gwen and Frank, Mark and Lainscsek, Claudia and Fasel, Ian and Movellan, Javier},
  booktitle={2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)},
  volume={2},
  pages={568--573},
  year={2005},
  organization={IEEE}
}

@inproceedings{mobilenet,
  title={Searching for mobilenetv3},
  author={Howard, Andrew and Sandler, Mark and Chu, Grace and Chen, Liang-Chieh and Chen, Bo and Tan, Mingxing and Wang, Weijun and Zhu, Yukun and Pang, Ruoming and Vasudevan, Vijay and others},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={1314--1324},
  year={2019}
}

@inproceedings{socher2013recursive,
  title={Recursive deep models for semantic compositionality over a sentiment treebank},
  author={Socher, Richard and Perelygin, Alex and Wu, Jean and Chuang, Jason and Manning, Christopher D and Ng, Andrew Y and Potts, Christopher},
  booktitle={Proceedings of the 2013 conference on empirical methods in natural language processing},
  pages={1631--1642},
  year={2013}
}

@article{wolf2019huggingface,
  title={Huggingface's transformers: State-of-the-art natural language processing},
  author={Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, R{\'e}mi and Funtowicz, Morgan and others},
  journal={arXiv preprint arXiv:1910.03771},
  year={2019}
}

@article{floridi2020gpt,
  title={GPT-3: Its nature, scope, limits, and consequences},
  author={Floridi, Luciano and Chiriatti, Massimo},
  journal={Minds and Machines},
  volume={30},
  number={4},
  pages={681--694},
  year={2020},
  publisher={Springer}
}

@article{distilbert,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author={Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
  journal={arXiv preprint arXiv:1910.01108},
  year={2019}
}

@article{polino2018model,
  title={Model compression via distillation and quantization},
  author={Polino, Antonio and Pascanu, Razvan and Alistarh, Dan},
  journal={arXiv preprint arXiv:1802.05668},
  year={2018}
}

@inproceedings{mullapudi2019online,
  title={Online model distillation for efficient video inference},
  author={Mullapudi, Ravi Teja and Chen, Steven and Zhang, Keyi and Ramanan, Deva and Fatahalian, Kayvon},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3573--3582},
  year={2019}
}

@inproceedings{qiu2014ensemble,
  title={Ensemble deep learning for regression and time series forecasting},
  author={Qiu, Xueheng and Zhang, Le and Ren, Ye and Suganthan, Ponnuthurai N and Amaratunga, Gehan},
  booktitle={2014 IEEE symposium on computational intelligence in ensemble learning (CIEL)},
  pages={1--6},
  year={2014},
  organization={IEEE}
}


@misc{azure-spot,
	howpublished = {\url{https://azure.microsoft.com/en-in/products/virtual-machines/spot/}},
	title = {{Microsoft Azure Spot VMs}}}

@misc{aws-spot,
	howpublished = {\url{ https://aws.amazon.com/ec2/spot/}},
	title = {{Amazon Web Services Spot VMs}}}

@inproceedings{gupta2020deeprecsys,
  title={Deeprecsys: A system for optimizing end-to-end at-scale neural recommendation inference},
  author={Gupta, Udit and Hsia, Samuel and Saraph, Vikram and Wang, Xiaodong and Reagen, Brandon and Wei, Gu-Yeon and Lee, Hsien-Hsin S and Brooks, David and Wu, Carole-Jean},
  booktitle={2020 ACM/IEEE 47th Annual International Symposium on Computer Architecture (ISCA)},
  pages={982--995},
  year={2020},
  organization={IEEE}
}

@article{liu2014effects,
  title={The effects of interactive latency on exploratory visual analysis},
  author={Liu, Zhicheng and Heer, Jeffrey},
  journal={IEEE transactions on visualization and computer graphics},
  volume={20},
  number={12},
  pages={2122--2131},
  year={2014},
  publisher={IEEE}
}

@misc{azure-pricing,
	howpublished = {\url{https://azure.microsoft.com/en-in/pricing/details/virtual-machines/linux/}},
	title = {{Azure VM Pricing}}}

@article{wang2019language,
  title={Language models with transformers},
  author={Wang, Chenguang and Li, Mu and Smola, Alexander J},
  journal={arXiv preprint arXiv:1904.09408},
  year={2019}
}

@article{wang2019language1,
  title={Language models with transformers},
  author={Wang, Chenguang and Li, Mu and Smola, Alexander J},
  journal={arXiv preprint arXiv:1904.09408},
  year={2019}
}

@article{mark,
  title={Enabling cost-effective, slo-aware machine learning inference serving on public cloud},
  author={Zhang, Chengliang and Yu, Minchen and Wang, Wei and Yan, Feng},
  journal={IEEE Transactions on Cloud Computing},
  volume={10},
  number={3},
  pages={1765--1779},
  year={2020},
  publisher={IEEE}
}

@inproceedings{resnet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{vgg,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}

@inproceedings{regnet,
  title={RegNet: Multimodal sensor registration using deep neural networks},
  author={Schneider, Nick and Piewak, Florian and Stiller, Christoph and Franke, Uwe},
  booktitle={2017 IEEE intelligent vehicles symposium (IV)},
  pages={1803--1810},
  year={2017},
  organization={IEEE}
}

@inproceedings{resnext,
  title={Aggregated residual transformations for deep neural networks},
  author={Xie, Saining and Girshick, Ross and Doll{\'a}r, Piotr and Tu, Zhuowen and He, Kaiming},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1492--1500},
  year={2017}
}

@article{wide-resnet,
  title={Wide residual networks},
  author={Zagoruyko, Sergey and Komodakis, Nikos},
  journal={arXiv preprint arXiv:1605.07146},
  year={2016}
}

@article{roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}

@article{electra,
  title={Electra: Pre-training text encoders as discriminators rather than generators},
  author={Clark, Kevin and Luong, Minh-Thang and Le, Quoc V and Manning, Christopher D},
  journal={arXiv preprint arXiv:2003.10555},
  year={2020}
}

@inproceedings{xlm-roberta,
  title={Unsupervised Cross-lingual Representation Learning at Scale},
  author={Alexis Conneau and Kartikay Khandelwal and Naman Goyal and Vishrav Chaudhary and Guillaume Wenzek and Francisco Guzm{\'a}n and Edouard Grave and Myle Ott and Luke Zettlemoyer and Veselin Stoyanov},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  year={2019}
}

@article{xlnet,
  title={Xlnet: Generalized autoregressive pretraining for language understanding},
  author={Yang, Zhilin and Dai, Zihang and Yang, Yiming and Carbonell, Jaime and Salakhutdinov, Russ R and Le, Quoc V},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{albert,
  title={Albert: A lite bert for self-supervised learning of language representations},
  author={Lan, Zhenzhong and Chen, Mingda and Goodman, Sebastian and Gimpel, Kevin and Sharma, Piyush and Soricut, Radu},
  journal={arXiv preprint arXiv:1909.11942},
  year={2019}
}

@article{funnel-trans,
  title={Funnel-transformer: Filtering out sequential redundancy for efficient language processing},
  author={Dai, Zihang and Lai, Guokun and Yang, Yiming and Le, Quoc},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={4271--4282},
  year={2020}
}

@article{deberta,
  title={Deberta: Decoding-enhanced bert with disentangled attention},
  author={He, Pengcheng and Liu, Xiaodong and Gao, Jianfeng and Chen, Weizhu},
  journal={arXiv preprint arXiv:2006.03654},
  year={2020}
}



@INPROCEEDINGS{kaimingrectifier,  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},  booktitle={2015 IEEE International Conference on Computer Vision (ICCV)},   title={Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification},   year={2015},  volume={},  number={},  pages={1026-1034},  doi={10.1109/ICCV.2015.123}}

@misc{self:attn:on2:memory,
      title={Self-attention Does Not Need $O(n^2)$ Memory}, 
      author={Markus N. Rabe and Charles Staats},
      year={2022},
      eprint={2112.05682},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{flexgen,
      title={{FlexGen}: High-Throughput Generative Inference of Large Language Models with a Single GPU}, 
      author={Ying Sheng and Lianmin Zheng and Binhang Yuan and Zhuohan Li and Max Ryabinin and Daniel Y. Fu and Zhiqiang Xie and Beidi Chen and Clark Barrett and Joseph E. Gonzalez and Percy Liang and Christopher Ré and Ion Stoica and Ce Zhang},
      year={2023},
      eprint={2303.06865},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{efficiently-scaling-transformer-inference,
      title={Efficiently Scaling Transformer Inference}, 
      author={Reiner Pope and Sholto Douglas and Aakanksha Chowdhery and Jacob Devlin and James Bradbury and Anselm Levskaya and Jonathan Heek and Kefan Xiao and Shivani Agrawal and Jeff Dean},
      year={2022},
      eprint={2211.05102},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings {orca,
    author = {Gyeong-In Yu and Joo Seong Jeong and Geon-Woo Kim and Soojeong Kim and Byung-Gon Chun},
    title = {{Orca: A Distributed Serving System for Transformer-Based Generative Models}},
    booktitle = {OSDI},
    year = {2022},
}

@misc{xformers,
howpublished = {\url{https://facebookresearch.github.io/xformers/components/ops.html}},
title = {{XFORMERS OPTIMIZED OPERATORS}}
}

@misc{fastserve,
      title={Fast Distributed Inference Serving for Large Language Models}, 
      author={Bingyang Wu and Yinmin Zhong and Zili Zhang and Gang Huang and Xuanzhe Liu and Xin Jin},
      year={2023},
      eprint={2305.05920},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{retnet,
      title={Retentive Network: A Successor to Transformer for Large Language Models}, 
      author={Yutao Sun and Li Dong and Shaohan Huang and Shuming Ma and Yuqing Xia and Jilong Xue and Jianyong Wang and Furu Wei},
      year={2023},
      eprint={2307.08621},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{largescalemoe,
      title={Efficient Large Scale Language Modeling with Mixtures of Experts}, 
      author={Mikel Artetxe and Shruti Bhosale and Naman Goyal and Todor Mihaylov and Myle Ott and Sam Shleifer and Xi Victoria Lin and Jingfei Du and Srinivasan Iyer and Ramakanth Pasunuru and Giri Anantharaman and Xian Li and Shuohui Chen and Halil Akin and Mandeep Baines and Louis Martin and Xing Zhou and Punit Singh Koura and Brian O'Horo and Jeff Wang and Luke Zettlemoyer and Mona Diab and Zornitsa Kozareva and Ves Stoyanov},
      year={2022},
      eprint={2112.10684},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{multiqueryattention,
      title={Fast Transformer Decoding: One Write-Head is All You Need}, 
      author={Noam Shazeer},
      year={2019},
      eprint={1911.02150},
      archivePrefix={arXiv},
      primaryClass={cs.NE}
}

@misc{dao2023flash,
    title={{Flash-decoding for long-context inference}},
    author={Dao, Tri and Haziza, Daniel and Massa, Francisco and Sizov, Grigory},
    year={2023},
    publisher={\url{https://pytorch.org/blog/flash-decoding/}}
}

@inproceedings{hwang2021elastic,
  title={Elastic resource sharing for distributed deep learning},
  author={Hwang, Changho and Kim, Taehyun and Kim, Sunghyun and Shin, Jinwoo and Park, KyoungSoo},
  booktitle={18th USENIX Symposium on Networked Systems Design and Implementation (NSDI 21)},
  pages={721--739},
  year={2021}
}

@misc{vLLM:github,
    title = {{vLLM: Easy, fast, and cheap LLM serving for everyone}},
    howpublished = {\url{https://github.com/vllm-project/vllm}},
}

@misc{lightllm:github,
    howpublished = {\url{https://github.com/ModelTC/lightllm}},
    title = {{LightLLM: A Light and Fast Inference Service for LLM}}
}

@misc{llmperf:github,
    howpublished = {\url{https://github.com/ray-project/llmperf}},
    title = {{LLMPerf: A Tool for evaulation the performance of LLM APIs}}
}

@misc{fastertransformer,
    howpublished = {\url{https://github.com/NVIDIA/FasterTransformer}},
    title = {{Faster Transformer}}
}

@misc{anyscale,
    howpublished = {\url{https://www.anyscale.com}},
    title = {{AnyScale}}
}

@misc{fireworks,
    howpublished = {\url{https://fireworks.ai}},
    title = {Fireworks}
}

@misc{groq,
    howpublished = {\url{https://groq.com}},
    title = {Groq}
}

@misc{multinodeinferenceblog,
    howpublished = {\url{https://core.vmware.com/blog/using-nvidias-aiml-frameworks-generative-ai-vmware-vsphere}},
    title = {{Using NVIDIA's AI/ML Frameworks for Generative AI on VMware vSphere}}
}

@misc{largecontextlength,
    howpublished = {\url{https://blog.gopenai.com/how-to-speed-up-llms-and-use-100k-context-window-all-tricks-in-one-place-ffd40577b4c}},
    title = {{The Secret Sauce behind 100K context window in LLMs: all tricks in one place}}
}

@inproceedings{tritonpaper,
    author = {Tillet, Philippe and Kung, H. T. and Cox, David},
    title = {{Triton: An Intermediate Language and Compiler for Tiled Neural Network Computations}},
    year = {2019},
    isbn = {9781450367196},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3315508.3329973},
    doi = {10.1145/3315508.3329973},
    abstract = {XXX.},
    booktitle = {Proceedings of the 3rd ACM SIGPLAN International Workshop on Machine Learning and Programming Languages},
    pages = {10–19},
    numpages = {10},
    keywords = {compiler, neural networks, GPU},
    location = {Phoenix, AZ, USA},
    series = {MAPL 2019}
}


@inproceedings{varuna,
  title={{Varuna: scalable, low-cost training of massive deep learning models}},
  author={Athlur, Sanjith and Saran, Nitika and Sivathanu, Muthian and Ramjee, Ramachandran and Kwatra, Nipun},
  booktitle={EuroSys},
  year={2022}
}

@inproceedings{pipedream,
    title={{PipeDream: generalized pipeline parallelism for DNN training}},
    author={Narayanan, Deepak and Harlap, Aaron and Phanishayee, Amar and Seshadri, Vivek and Devanur, Nikhil R and Ganger, Gregory R and Gibbons, Phillip B and Zaharia, Matei},
    booktitle={SOSP},
    year={2019}
}

@article{megatron,
    title={Megatron-LM: Training multi-billion parameter language models using gpu model parallelism},
    author={Shoeybi, Mohammad and Patwary, Mostofa and Puri, Raul and LeGresley, Patrick and Casper, Jared and Catanzaro, Bryan},
    journal={arXiv preprint arXiv:1909.08053},
    year={2019}
}

@article{giraffe,
    title={{Giraffe: Adventures in Expanding Context Lengths in LLMs}},
    author={Arka Pal and Deep Karkhanis and Manley Roberts and Samuel Dooley and Arvind Sundararajan and Siddartha Naidu},
    journal={arXiv preprint arXiv:2308.10882},
    year={2019}
}

@article{gpt3-brown2020language,
    title={Language models are few-shot learners},
    author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
    journal={Advances in neural information processing systems},
    volume={33},
    pages={1877--1901},
    year={2020}
}

@article{chowdhery2022Palm,
  author       = {Aakanksha Chowdhery and
                  Sharan Narang and
                  Jacob Devlin and
                  Maarten Bosma and
                  Gaurav Mishra and
                  Adam Roberts and
                  Paul Barham and
                  Hyung Won Chung and
                  Charles Sutton and
                  Sebastian Gehrmann and
                  Parker Schuh and
                  Kensen Shi and
                  Sasha Tsvyashchenko and
                  Joshua Maynez and
                  Abhishek Rao and
                  Parker Barnes and
                  Yi Tay and
                  Noam Shazeer and
                  Vinodkumar Prabhakaran and
                  Emily Reif and
                  Nan Du and
                  Ben Hutchinson and
                  Reiner Pope and
                  James Bradbury and
                  Jacob Austin and
                  Michael Isard and
                  Guy Gur{-}Ari and
                  Pengcheng Yin and
                  Toju Duke and
                  Anselm Levskaya and
                  Sanjay Ghemawat and
                  Sunipa Dev and
                  Henryk Michalewski and
                  Xavier Garcia and
                  Vedant Misra and
                  Kevin Robinson and
                  Liam Fedus and
                  Denny Zhou and
                  Daphne Ippolito and
                  David Luan and
                  Hyeontaek Lim and
                  Barret Zoph and
                  Alexander Spiridonov and
                  Ryan Sepassi and
                  David Dohan and
                  Shivani Agrawal and
                  Mark Omernick and
                  Andrew M. Dai and
                  Thanumalayan Sankaranarayana Pillai and
                  Marie Pellat and
                  Aitor Lewkowycz and
                  Erica Moreira and
                  Rewon Child and
                  Oleksandr Polozov and
                  Katherine Lee and
                  Zongwei Zhou and
                  Xuezhi Wang and
                  Brennan Saeta and
                  Mark Diaz and
                  Orhan Firat and
                  Michele Catasta and
                  Jason Wei and
                  Kathy Meier{-}Hellstern and
                  Douglas Eck and
                  Jeff Dean and
                  Slav Petrov and
                  Noah Fiedel},
  title        = {PaLM: Scaling Language Modeling with Pathways},
  journal      = {CoRR},
  volume       = {abs/2204.02311},
  year         = {2022},
  url          = {https://doi.org/10.48550/arXiv.2204.02311},
  doi          = {10.48550/arXiv.2204.02311},
  eprinttype    = {arXiv},
  eprint       = {2204.02311},
  timestamp    = {Wed, 16 Aug 2023 16:10:28 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2204-02311.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{kaplan2020scalinglaws,
  author       = {Jared Kaplan and
                  Sam McCandlish and
                  Tom Henighan and
                  Tom B. Brown and
                  Benjamin Chess and
                  Rewon Child and
                  Scott Gray and
                  Alec Radford and
                  Jeffrey Wu and
                  Dario Amodei},
  title        = {Scaling Laws for Neural Language Models},
  journal      = {CoRR},
  volume       = {abs/2001.08361},
  year         = {2020},
  url          = {https://arxiv.org/abs/2001.08361},
  eprinttype    = {arXiv},
  eprint       = {2001.08361},
  timestamp    = {Wed, 03 Jun 2020 10:55:13 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2001-08361.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{wei2022emergent,
  author       = {Jason Wei and
                  Yi Tay and
                  Rishi Bommasani and
                  Colin Raffel and
                  Barret Zoph and
                  Sebastian Borgeaud and
                  Dani Yogatama and
                  Maarten Bosma and
                  Denny Zhou and
                  Donald Metzler and
                  Ed H. Chi and
                  Tatsunori Hashimoto and
                  Oriol Vinyals and
                  Percy Liang and
                  Jeff Dean and
                  William Fedus},
  title        = {Emergent Abilities of Large Language Models},
  journal      = {Trans. Mach. Learn. Res.},
  volume       = {2022},
  year         = {2022},
  url          = {https://openreview.net/forum?id=yzkSU5zdwD},
  timestamp    = {Fri, 19 May 2023 11:20:41 +0200},
  biburl       = {https://dblp.org/rec/journals/tmlr/WeiTBRZBYBZMCHVLDF22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{openai2022gpt4techreport,
  author       = {OpenAI},
  title        = {{GPT-4} Technical Report},
  journal      = {CoRR},
  volume       = {abs/2303.08774},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2303.08774},
  doi          = {10.48550/arXiv.2303.08774},
  eprinttype    = {arXiv},
  eprint       = {2303.08774},
  timestamp    = {Mon, 20 Mar 2023 15:23:19 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2303-08774.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{openai,
  title = {OpenAI},
  howpublished = {\url{https://openai.com/}},
}

@misc{openaiapi,
  title = {OpenAI API},
  howpublished = {\url{https://platform.openai.com/docs/api-reference/introduction}},
}

@misc{fireworksai,
  title = {Fireworks: Generative AI for Product Innovation!},
  howpublished = {\url{https://fireworks.ai/}},
}

@misc{azureaistudio,
  title = {{Azure AI Studio: A unified platform for developing and deploying generative AI apps responsibly
}},
  howpublished = {\url{https://azure.microsoft.com/en-in/products/ai-studio}},
}

@misc{chatgpt,
  title = {ChatGPT},
  howpublished = {{https://chat.openai.com}},
}

@misc{claudeai,
  title = {Anthropic Claude},
  howpublished = {\url{https://claude.ai}},
}

@misc{characterai,
  title = {{Character AI}},
  howpublished = {\url{https://character.ai}},
}
@misc{bingai,
  title = {{Bing AI}},
  howpublished = {\url{https://www.bing.com/chat}},
}
@misc{nccl,
  title = {NVIDIA Collective Communications Library (NCCL)},
  howpublished = {\url{https://developer.nvidia.com/nccl}},
}

@misc{nvidiadgx,
  title = {NVIDIA DGX Platform},
  howpublished = {\url{https://www.nvidia.com/en-us/data-center/dgx-platform/}},
}

@misc{komoai,
  title = {Komo},
  howpublished = {\url{https://komo.ai/}},
}

@misc{youdotcom,
  title = {You.com},
  howpublished = {\url{https://you.com/}},
}

@misc{perplexityai,
  title = {Perplexity AI},
  howpublished = {\url{https://www.perplexity.ai/}},
}

@misc{bard,
  title = {{Google Bard}},
  howpublished = {\url{https://bard.google.com}},
}

@misc{githubcopilot,
  title = {Github Copilot},
  howpublished = {\url{https://github.com/features/copilot}},
}

@misc{microsoftcopilot,
  title = {{Microsoft Copilot}},
  howpublished = {\url{https://www.microsoft.com/en-us/microsoft-copilot}},
}

@misc{googleduetai,
  title = {Google Duet AI},
  howpublished = {\url{https://workspace.google.com/solutions/ai/}},
}
@misc{arxiv,
  title = {arXiv.org e-Print archive},
  howpublished = {\url{https://arxiv.org/}},
}
@misc{replitghostwriter,
  title = {Replit Ghostwriter},
  howpublished = {\url{https://replit.com/site/ghostwriter}},
}

@misc{amazoncodewhisperer,
  title = {Amazon CodeWhisperer},
  howpublished = {\url{https://aws.amazon.com/codewhisperer/}},
}

@misc{tile-quantization,
  title = {Matrix Multiplication Background User's Guide},
  howpublished = {\url{https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html}},
}

@misc{nanogpt,
  title = {nanoGPT},
  howpublished = {\url{https://github.com/karpathy/nanoGPT}},
}

@misc{touvron2023llama,
      title={{Llama 2: Open Foundation and Fine-Tuned Chat Models}}, 
      author={Hugo Touvron and Louis Martin and Kevin Stone and Peter Albert and Amjad Almahairi and Yasmine Babaei and Nikolay Bashlykov and Soumya Batra and Prajjwal Bhargava and Shruti Bhosale and Dan Bikel and Lukas Blecher and Cristian Canton Ferrer and Moya Chen and Guillem Cucurull and David Esiobu and Jude Fernandes and Jeremy Fu and Wenyin Fu and Brian Fuller and Cynthia Gao and Vedanuj Goswami and Naman Goyal and Anthony Hartshorn and Saghar Hosseini and Rui Hou and Hakan Inan and Marcin Kardas and Viktor Kerkez and Madian Khabsa and Isabel Kloumann and Artem Korenev and Punit Singh Koura and Marie-Anne Lachaux and Thibaut Lavril and Jenya Lee and Diana Liskovich and Yinghai Lu and Yuning Mao and Xavier Martinet and Todor Mihaylov and Pushkar Mishra and Igor Molybog and Yixin Nie and Andrew Poulton and Jeremy Reizenstein and Rashi Rungta and Kalyan Saladi and Alan Schelten and Ruan Silva and Eric Michael Smith and Ranjan Subramanian and Xiaoqing Ellen Tan and Binh Tang and Ross Taylor and Adina Williams and Jian Xiang Kuan and Puxin Xu and Zheng Yan and Iliyan Zarov and Yuchen Zhang and Angela Fan and Melanie Kambadur and Sharan Narang and Aurelien Rodriguez and Robert Stojnic and Sergey Edunov and Thomas Scialom},
      year={2023},
      eprint={2307.09288},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{llama3blog,
  title = {{Meta Llama 3: The most capable openly available LLM to date}},
  howpublished = {\url{https://ai.meta.com/blog/meta-llama-3/}},
}

@misc{almazrouei2023falcon,
      title={{The Falcon Series of Open Language Models}}, 
      author={Ebtesam Almazrouei and Hamza Alobeidli and Abdulaziz Alshamsi and Alessandro Cappelli and Ruxandra Cojocaru and Mérouane Debbah and Étienne Goffinet and Daniel Hesslow and Julien Launay and Quentin Malartic and Daniele Mazzotta and Badreddine Noune and Baptiste Pannier and Guilherme Penedo},
      year={2023},
      eprint={2311.16867},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{cohan-etal-2018-discourse,
  title = "A Discourse-Aware Attention Model for Abstractive Summarization of Long Documents",
  author = "Cohan, Arman  and
    Dernoncourt, Franck  and
    Kim, Doo Soon  and
    Bui, Trung  and
    Kim, Seokhwan  and
    Chang, Walter  and
    Goharian, Nazli",
  booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)",
  month = jun,
  year = "2018",
  address = "New Orleans, Louisiana",
  publisher = "Association for Computational Linguistics",
  url = "https://aclanthology.org/N18-2097",
  doi = "10.18653/v1/N18-2097",
  pages = "615--621",
}

@misc{zheng2023lmsyschat1m,
      title={LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset}, 
      author={Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Tianle Li and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zhuohan Li and Zi Lin and Eric. P Xing and Joseph E. Gonzalez and Ion Stoica and Hao Zhang},
      year={2023},
      eprint={2309.11998},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{gpt3,
  title = {OpenAI GPT-3: Understanding the Architecture},
  howpublished = {\url{https://www.theaidream.com/post/openai-gpt-3-understanding-the-architecture}},
}

@misc{llmperfdatabricks,
  title = {LLM Inference Performance Engineering: Best Practices},
  howpublished = {\url{https://www.databricks.com/blog/llm-inference-performance-engineering-best-practices}},
}

@misc{hftgi,
  title = {Text Generation Inference},
  howpublished = {\url{https://huggingface.co/text-generation-inference}},
}

@misc{deepspeed-multigpu,
  title = {DeepSpeed Inference: Multi-GPU inference with customized inference kernels and quantization support},
  howpublished = {\url{https://www.deepspeed.ai/2021/03/15/inference-kernel-optimization.html}},
}


@misc{gptq,
      title={GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers}, 
      author={Elias Frantar and Saleh Ashkboos and Torsten Hoefler and Dan Alistarh},
      year={2023},
      eprint={2210.17323},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{smoothquant,
      title={SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models}, 
      author={Guangxuan Xiao and Ji Lin and Mickael Seznec and Hao Wu and Julien Demouth and Song Han},
      year={2023},
      eprint={2211.10438},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{llmint8,
      title={LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale}, 
      author={Tim Dettmers and Mike Lewis and Younes Belkada and Luke Zettlemoyer},
      year={2022},
      eprint={2208.07339},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{moedeployment,
      title={Towards MoE Deployment: Mitigating Inefficiencies in Mixture-of-Expert (MoE) Inference}, 
      author={Haiyang Huang and Newsha Ardalani and Anna Sun and Liu Ke and Hsien-Hsin S. Lee and Anjali Sridhar and Shruti Bhosale and Carole-Jean Wu and Benjamin Lee},
      year={2023},
      eprint={2303.06182},
      archivePrefix={arXiv},
      primaryClass={cs.DC}
}

@inproceedings {moeatc23,
author = {Jiamin Li and Yimin Jiang and Yibo Zhu and Cong Wang and Hong Xu},
title = {{Accelerating Distributed MoE Training and Inference with Lina}},
booktitle = {USENIX ATC},
year = {2023},
}

@inproceedings{coconetasplos,
    author = {Jangda, Abhinav and Huang, Jun and Liu, Guodong and Sabet, Amir Hossein Nodehi and Maleki, Saeed and Miao, Youshan and Musuvathi, Madanlal and Mytkowicz, Todd and Saarikivi, Olli},
    title = {{Breaking the Computation and Communication Abstraction Barrier in Distributed Machine Learning Workloads}},
    year = {2022},
    booktitle = {ASPLOS}
}

@inproceedings{googleoverlap,
    author = {Wang, Shibo and Wei, Jinliang and Sabne, Amit and Davis, Andy and Ilbeyi, Berkin and Hechtman, Blake and Chen, Dehao and Murthy, Karthik Srinivasa and Maggioni, Marcello and Zhang, Qiao and Kumar, Sameer and Guo, Tongfei and Xu, Yuanzhong and Zhou, Zongwei},
    title = {{Overlap Communication with Dependent Computation via Decomposition in Large Deep Learning Models}},
    year = {2022},
    booktitle = {ASPLOS},
}

@inproceedings{batchmakereurosys,
    author = {Gao, Pin and Yu, Lingfan and Wu, Yongwei and Li, Jinyang},
    title = {{Low Latency RNN Inference with Cellular Batching}},
    year = {2018},
    booktitle = {EuroSys},
}

@misc{tensorflowserving,
      title={TensorFlow-Serving: Flexible, High-Performance ML Serving}, 
      author={Christopher Olston and Noah Fiedel and Kiril Gorovoy and Jeremiah Harmsen and Li Lao and Fangwei Li and Vinu Rajashekhar and Sukriti Ramesh and Jordan Soyke},
      year={2017},
      eprint={1712.06139},
      archivePrefix={arXiv},
      primaryClass={cs.DC}
}

@inproceedings{lightseq,
    title = {{LightSeq: A High Performance Inference Library for Transformers}},
    author = "Wang, Xiaohui and Xiong, Ying and Wei, Yang and Wang, Mingxuan and Li, Lei",
    booktitle = "NAACL-HLT",
    year = "2021",
}

@misc{groupedqueryattention,
      title={{GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints}}, 
      author={Joshua Ainslie and James Lee-Thorp and Michiel de Jong and Yury Zemlyanskiy and Federico Lebrón and Sumit Sanghai},
      year={2023},
      eprint={2305.13245},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{longformer,
      title={{Longformer: The Long-Document Transformer}}, 
      author={Iz Beltagy and Matthew E. Peters and Arman Cohan},
      year={2020},
      eprint={2004.05150},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{jiang2023mistral,
      title={{Mistral 7B}},
      author={Jiang, Albert Q and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and others},
      journal={arXiv preprint arXiv:2310.06825},
      year={2023}
}

@misc{yi,
    howpublished = {\url{https://huggingface.co/01-ai/Yi-34B-200K}},
    title = {{Yi series of large language models trained from scratch by developers at 01.AI.}}
}

@inproceedings{heavyhitters,
    title={{\$H\_2O\$: Heavy-Hitter Oracle for Efficient Generative Inference of Large Language Models}},
    author={Zhenyu Zhang and Ying Sheng and Tianyi Zhou and Tianlong Chen and Lianmin Zheng and Ruisi Cai and Zhao Song and Yuandong Tian and Christopher Re and Clark Barrett and Zhangyang Wang and Beidi Chen},
    booktitle={Conference on Parsimony and Learning (Recent Spotlight Track)},
    year={2023},
    url={https://openreview.net/forum?id=w4IRMAJYPk}
}

@inproceedings{arachneosdi,
    author = {Henry Qin and Qian Li and Jacqueline Speiser and Peter Kraft and John Ousterhout},
    title = {{Arachne: Core-Aware Thread Management}},
    booktitle = {OSDI},
    year = {2018},
}

@inproceedings{shenango,
    author = {Ousterhout, Amy and Fried, Joshua and Behrens, Jonathan and Belay, Adam and Balakrishnan, Hari},
    title = {{Shenango: Achieving High CPU Efficiency for Latency-Sensitive Datacenter Workloads}},
    year = {2019},
    booktitle = {NSDI}
}

@inproceedings{ingens,
    author = {Youngjin Kwon and Hangchen Yu and Simon Peter and Christopher J. Rossbach and Emmett Witchel},
    title = {{Coordinated and Efficient Huge Page Management with Ingens}},
    booktitle = {OSDI},
    year = {2016},
}

@inproceedings{hawkeye,
    author = {Panwar, Ashish and Bansal, Sorav and Gopinath, K.},
    title = {HawkEye: Efficient Fine-Grained OS Support for Huge Pages},
    year = {2019},
    booktitle = {ASPLOS},
}

@misc{sarathi2023,
      title={{SARATHI: Efficient LLM Inference by Piggybacking Decodes with Chunked Prefills}}, 
      author={Amey Agrawal and Ashish Panwar and Jayashree Mohan and Nipun Kwatra and Bhargav S. Gulavani and Ramachandran Ramjee},
      year={2023},
      eprint={2308.16369},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{agrawal2024taming,
      title={{Taming Throughput-Latency Tradeoff in LLM Inference with Sarathi-Serve}},
      author={Agrawal, Amey and Kedia, Nitin and Panwar, Ashish and Mohan, Jayashree and Kwatra, Nipun and Gulavani, Bhargav S and Tumanov, Alexey and Ramjee, Ramachandran},
      journal={OSDI},
      year={2024}
}

@misc{gelu2023,
      title={Gaussian Error Linear Units (GELUs)}, 
      author={Dan Hendrycks and Kevin Gimpel},
      year={2023},
      eprint={1606.08415},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{relu2019,
      title={Deep Learning using Rectified Linear Units (ReLU)}, 
      author={Abien Fred Agarap},
      year={2019},
      eprint={1803.08375},
      archivePrefix={arXiv},
      primaryClass={cs.NE}
}

@article{abhyankar2024apiserve,
      title={{APIServe: Efficient API Support for Large-Language Model Inferencing}},
      author={Abhyankar, Reyna and He, Zijian and Srivatsa, Vikranth and Zhang, Hao and Zhang, Yiying},
      journal={arXiv preprint arXiv:2402.01869},
      year={2024}
}

@misc{lmsyschat1m,
      title={LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset}, 
      author={Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Tianle Li and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zhuohan Li and Zi Lin and Eric. P Xing and Joseph E. Gonzalez and Ion Stoica and Hao Zhang},
      year={2023},
      eprint={2309.11998},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@inproceedings{jiang-etal-2023-discourse,
      title="Discourse Centric Evaluation of Machine Translation with a Densely Annotated Parallel Corpus", 
      author="Yuchen Eleanor Jiang and Tianyu Liu and Shuming Ma and Dongdong Zhang and Ryan Cotterell and Mrinmaya Sachan",
      booktitle = "Proceedings of the 2023 Conference of the Association for Computational Linguistics: Human Language Technologies",
      month = jul,
      year = "2023",
      address = "Toronto, Canada",
      publisher = "Association for Computational Linguistics",
      url = "https://aclanthology.org/2023.acl-main.111",
      doi = "10.18653/v1/2023.main.111",
      pages = "1550--1565",
}

@Inbook{Erickson2022,
    author="Erickson, Jeremy P. and Anderson, James H.",
    editor="Tian, Yu-Chu
    and Levy, David Charles",
    title="Soft Real-Time Scheduling",
    bookTitle="Handbook of Real-Time Computing",
    year="2022",
    publisher="Springer Nature Singapore",
    address="Singapore",
}

@misc{jiang2024mixtral,
      title={{Mixtral of Experts}}, 
      author={Albert Q. Jiang and Alexandre Sablayrolles and Antoine Roux and Arthur Mensch and Blanche Savary and Chris Bamford and Devendra Singh Chaplot and Diego de las Casas and Emma Bou Hanna and Florian Bressand and Gianna Lengyel and Guillaume Bour and Guillaume Lample and Lélio Renard Lavaud and Lucile Saulnier and Marie-Anne Lachaux and Pierre Stock and Sandeep Subramanian and Sophia Yang and Szymon Antoniak and Teven Le Scao and Théophile Gervet and Thibaut Lavril and Thomas Wang and Timothée Lacroix and William El Sayed},
      year={2024},
      eprint={2401.04088},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@InProceedings{pmlr-v202-leviathan23a,
  title = 	 {Fast Inference from Transformers via Speculative Decoding},
  author =       {Leviathan, Yaniv and Kalman, Matan and Matias, Yossi},
  booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
  pages = 	 {19274--19286},
  year = 	 {2023},
  editor = 	 {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume = 	 {202},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {23--29 Jul},
  publisher =    {PMLR},
}

@article{team2024gemini,
  title={{Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context}},
  author={Reid, M and Savinov, N and Teplyashin, D and Dmitry, Lepikhin and Lillicrap, T and Alayrac, JB and Soricut, R and Lazaridou, A and Firat, O and others},
  journal={arXiv preprint arXiv:2403.05530},
  year={2024}
}

@article{flashdecoding,
  title={{FlashDecoding++: Faster Large Language Model Inference on GPUs}},
  author={Ke Hong and Guohao Dai and Jiaming Xu and Qiuli Mao and Xiuhong Li and Jun Liu and Kangdi Chen and Yuhan Dong and Yu Wang},
  journal={arXiv preprint arXiv:2311.01282},
  year={2023}
}

@article{terapipe,
  title={{TeraPipe: Token-Level Pipeline Parallelism for Training Large-Scale Language Models}},
  author={Zhuohan Li and Siyuan Zhuang and Shiyuan Guo and Danyang Zhuo and Hao Zhang and Dawn Song and Ion Stoica},
  journal={arXiv preprint arXiv:2102.07988},
  year={2021}
}

@inproceedings{eggen2019thread,
  title={{Thread and process efficiency in Python}},
  author={Eggen, Roger and Eggen, Maurice},
  booktitle={PDPTA},
  year={2019},
}

@article{infiniband,
  title={{An introduction to the InfiniBand architecture}},
  author={Pfister, Gregory F},
  journal={High performance mass storage and parallel I/O},
  volume={42},
  number={617-632},
  pages={10},
  year={2001}
}

@article{sanovar2024lean,
  title={Lean Attention: Hardware-Aware Scalable Attention Mechanism for the Decode-Phase of Transformers},
  author={Sanovar, Rya and Bharadwaj, Srikant and Amant, Renee St and R{\"u}hle, Victor and Rajmohan, Saravan},
  journal={arXiv preprint arXiv:2405.10480},
  year={2024}
}

@article{su2024roformer,
  title={{Roformer: Enhanced transformer with rotary position embedding}},
  author={Su, Jianlin and Ahmed, Murtadha and Lu, Yu and Pan, Shengfeng and Bo, Wen and Liu, Yunfeng},
  journal={Neurocomputing},
  volume={568},
  year={2024},
}


@article{chowdhery2023palm,
  title={{PaLM: Scaling Language Modeling with Pathways}},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={Journal of Machine Learning Research},
  volume={24},
  number={240},
  pages={1--113},
  year={2023}
}

@article{onlinesoftmax,
  title={{Online normalizer calculation for softmax}},
  author={Milakov, Maxim and Gimelshein, Natalia},
  journal={arXiv preprint arXiv:1805.02867},
  year={2018}
}

@misc{ropescaling,
    title={{Enhancing LLM Context Length with RoPE Scaling}},
    author={Sparsh Bhasin},
    howpublished = {\url{https://blog.monsterapi.ai/blogs/enhancing-llm-context-length-with-rope-scaling}},
    year={2024}
}

@misc{lwm:github,
    title={{Large World Model (LWM)}},
    howpublished = {\url{https://github.com/LargeWorldModel/lwm}},
}

@misc{lwm,
      title={{World Model on Million-Length Video And Language With Blockwise RingAttention}},
      author={Hao Liu and Wilson Yan and Matei Zaharia and Pieter Abbeel},
      journal={arXiv preprint arXiv:2402.08268},
      year={2024}
}

@misc{gradientaiblog,
    title={{Scaling Rotational Embeddings for Long-Context Language Models}},
    author={Gradient team},
    howpublished = {\url{https://gradient.ai/blog/scaling-rotational-embeddings-for-long-context-language-models}},
}

@misc{geminicontextcaching,
    title={{Context caching}},
    author={Gemini team},
    howpublished = {\url{https://ai.google.dev/gemini-api/docs/caching}},
}

@misc{claudecontextcaching,
    title={{Prompt Caching (beta)}},
    author={Claude team},
    howpublished = {\url{https://docs.anthropic.com/en/docs/build-with-claude/prompt-caching}},
}

@misc{supermaven,
    title={{Announcing Supermaven 1.0}},
    author={Jacob Jackson},
    howpublished = {\url{https://supermaven.com/blog/announcing-supermaven-1.0}},
}

@misc{infinitellm,
  title={{Infinite-LLM: Efficient LLM Service for Long Context with DistAttention and Distributed KVCache}}, 
  author={Bin Lin and Chen Zhang and Tao Peng and Hanyu Zhao and Wencong Xiao and Minmin Sun and Anmin Liu and Zhipeng Zhang and Lanbo Li and Xiafei Qiu and Shen Li and Zhigang Ji and Tao Xie and Yong Li and Wei Lin},
  year={2024},
  eprint={2401.02669},
  archivePrefix={arXiv},
  primaryClass={cs.DC},
  url={https://arxiv.org/abs/2401.02669}, 
}

@article{fu2024efficient,
  title={{Efficient LLM Scheduling by Learning to Rank}},
  author={Fu, Yichao and Zhu, Siqi and Su, Runlong and Qiao, Aurick and Stoica, Ion and Zhang, Hao},
  journal={arXiv preprint arXiv:2408.15792},
  year={2024}
}

@article{wu2023fast,
  title={{Fast distributed inference serving for Large Language Models}},
  author={Wu, Bingyang and Zhong, Yinmin and Zhang, Zili and Liu, Shengyu and Liu, Fangyue and Sun, Yuanhang and Huang, Gang and Liu, Xuanzhe and Jin, Xin},
  journal={arXiv preprint arXiv:2305.05920},
  year={2023}
}

@article{kossmann2024gpu,
  title={{Is the GPU Half-Empty or Half-Full? Practical Scheduling Techniques for LLMs}},
  author={Kossmann, Ferdi and Fontaine, Bruce and Khudia, Daya and Cafarella, Michael and Madden, Samuel},
  journal={arXiv preprint arXiv:2410.17840},
  year={2024}
}

@inproceedings{sun2024llumnix,
  title={{Llumnix: Dynamic Scheduling for Large Language Model Serving}},
  author={Sun, Biao and Huang, Ziming and Zhao, Hanyu and Xiao, Wencong and Zhang, Xinyi and Li, Yong and Lin, Wei},
  booktitle={OSDI},
  year={2024}
}

@article{liu2024andes,
  title={{Andes: Defining and Enhancing Quality-of-Experience in LLM-Based Text Streaming Services}},
  author={Liu, Jiachen and Wu, Zhiyu and Chung, Jae-Won and Lai, Fan and Lee, Myungjin and Chowdhury, Mosharaf},
  journal={arXiv preprint arXiv:2404.16283},
  year={2024}
}


@article{jsq2,
    title = {{Analysis of join-the-shortest-queue routing for web server farms}},
    journal = {Performance Evaluation},
    volume = {64},
    number = {9},
    pages = {1062-1081},
    year = {2007},
    note = {Performance 2007},
    issn = {0166-5316},
    doi = {https://doi.org/10.1016/j.peva.2007.06.012},
    url = {https://www.sciencedirect.com/science/article/pii/S0166531607000624},
    author = {Varun Gupta and Mor {Harchol Balter} and Karl Sigman and Ward Whitt},
}


@inproceedings{jsq1,
    author={Weiping Zhu},
    booktitle={Proceedings Fourth International Conference/Exhibition on High Performance Computing in the Asia-Pacific Region}, 
    title={{Analysis of JSQ policy on soft real-time scheduling in cluster}}, 
    year={2000},
    volume={1},
    number={},
    pages={277-282 vol.1},
    doi={10.1109/HPC.2000.846562}
}

@inproceedings{dynamollm,
      title={{DynamoLLM: Designing LLM Inference Clusters for Performance and Energy Efficiency}}, 
      author={Jovan Stojkovic and Chaojie Zhang and Íñigo Goiri and Josep Torrellas and Esha Choukse},
      year={2025},
      booktitle={HPCA},
}

@article{yang2023cp,
  title={{Context Parallelism for Scalable Million-Token Inference}},
  author={Amy (Jie) Yang and Jingyi Yang and Aya Ibrahim and Xinfeng Xie and Bangsheng Tang and GrigorySizov and Jeremy Reizenstein and Jongsoo Park and Jianyu Huang},
  journal={arXiv preprint arXiv:2411.01783},
  year={2024}
}

@inproceedings{chen2025sharegpt4v,
  title={{ShareGPT4v: Improving Large Multi-Modal Models with Better Captions}},
  author={Chen, Lin and Li, Jinsong and Dong, Xiaoyi and Zhang, Pan and He, Conghui and Wang, Jiaqi and Zhao, Feng and Lin, Dahua},
  booktitle={ECCV},
  year={2025},
}

